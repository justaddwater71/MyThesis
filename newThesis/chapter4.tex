\chapter{Results and Analysis}

	\paragraph*{} After 19,782 tests producing 286,050 measurements for f-score and 19,782 measurements for accuracy, several notable results emerged.  Most importantly, a small number of method-feature combinations do exist that both provide a reasonable author detection accuracy and have a storage requirement of less than 16MB.  Further, in studying the effects of using the Google Web1T Corpus, Web1T did not provide enough classification benefit to justify its large storage requirement.  This does not mean that Web1T did not have a positive impact on accuracy, especially for the Enron corpus and naive Bayes.  It was also found that Web1T had different impacts on dissimilarly prolific authors than on similarly prolific authors. This chapter provides specific details about usable method-feature combinations and the impacts of Web1T.
	\paragraph*{} There is one notation convention used in this chapter that requires explanation.  The notation Web1T\% refers to the top percentage of the Web1T corpus used as the vocabulary in testing.  For instance, Web1T\% of 1 for OSB3 means that the top 1\% of orthogonal sparse bigrams of distance three (OSB3) were used as the vocabulary.  Web1T\% of 2 for GB3 means that the top 2\% of gappy bigrams of distance three (GB3) are used.  This pattern continues for Web1T\% of 4, 8, and 16 and feature types of 1-grams (GM1), 2-grams (GM2), and 5-grams (GM5).  The only special case is for Web1T\% of 0.  In this case, the Google Web1T Corpus was not used at all in constructing the vocabulary; the vocabulary is built using any and all tokens found in the training set.

\begin{singlespace}
\section{Most Effective Combination of Classification Methods, Feature Types, and Vocabulary}
\end{singlespace}
	\paragraph*{} Two measurements of effectiveness were used in this thesis: accuracy and f-score.  Since the accuracy for individual  authors is not the focus of this thesis, but rather the overall effectiveness of each classifier, feature type, and vocabulary combination, the f-score is averaged over authors for each combination.  In each test set, average accuracy was higher than MLE.  Likewise, average f-score was always lower than average accuracy.

	\paragraph*{} At this point, it would be natural to simply compare the highest accuracy for each method-feature-vocabulary combination in the thesis and determine which combination performed best.  Such an analysis would be flawed.  Due to the underlying data structure in the libLinear model, there is an absolute maximum number, $2^{31}$, of elements allowed.  The libLinear tool creates one element in its model for each author-token combination.  This means that for every author, there is a dedicated cell for each feature.  The data structure impact for the libLinear tool is array size; the number of authors multiplied by the number of features.  Array size in Java cannot exceed $2^{31}$. This limits the number of features that can be used with libLinear for a given number of authors. Figure \ref{fig:FeatureVSsize} shows the value of each feature-vocabulary-group combination.  Cells highlighted in red cannot be used with the LibLinear model.  If only the top $2^{31}$ features from each Web1T\% was used, then large Web1T\% values would have identical features.  For instance, two very large set are OSB3 for Web1T\% of 8 and Web1T\% of 16.  If only the top $2^{31}$ features were used from each of these features sets, then both of these sets, which far exceed $2^{31}$ features, would hold the same $2^{31}$ features.  This would create identical results and provide no additional insight into the true performance of that vocabulary. Therefore, due to the data structure limitation of the libLinear tool, there will be no LibLinear results for feature-author combinations that require an array larger than $2^{31}$ elements in the libLinear model.  
	

\begin{figure}[htbp!]
	\begin{center}
	\centering
	\includegraphics[scale=0.9]{FeatureVSsize}
	\caption{Liblinear Limits Due to Vocabulary Size and Group Size}
	\label{fig:FeatureVSsize}
	\end{center}
\end{figure}


	\paragraph*{}  While libLinear is the chosen SVM tool for this thesis, the classifier method being tested is SVM.  For the rest of this chapter, results will be analyzed by method instead of by tool.  For this reason, results will be discussed in terms of SVM and naive Bayes instead of in terms of libLinear and naive Bayes.

	\paragraph*{} The LibLinear maximum token-author pairs affects the average accuracies measured across feature types. The maximum token-author pairs limit causes large vocabularies to show a higher accuracy and f-score than smaller vocabularies.  This is not necessarily because the large vocabularies are more effective, but because the larger vocabularies do not have the lower accuracy and f-score outcomes of the large group sizes.  To illustrate this, the top twenty feature-method combinations are shown in Table \ref{tab:enron-accuracy-filtered-ranked} for the Enron E-mail Corpus.  The performance of each SVM OSB3-vocabulary combination is shown in Figure \ref{fig:plot-liblinear-enron-accuracy}. Using Table \ref{tab:twitter-accuracy-filtered-ranked} to evaluate accuracy would lead to a conclusion that SVM OSB3 has the best accuracy and f-score in this thesis.  However, plotting all OSB3 results for each Web1T\%  in \ref{fig:plot-liblinear-enron-accuracy} shows that all OSB3-vocabulary combinations perform along a similar curve.  The Web1T\% of 0 is actually able to execute, without any "index array out of bounds errors" due to the token-author pairs limit, against all group sizes (5, 10, 25, 50, 75, and 150) and, thus, appears to perform worse than other OSB3s in the table, but clearly performs similarly from Figure \ref{fig:plot-liblinear-enron-accuracy}.  From this example, it becomes clear that simply using the table values in Appendix A through Appendix D provides an insufficient analysis.  A better analysis is provided by examining the plots in Appendix Q through Appendix T.  
	
\begin{figure}[htbp!]
	\centering
	\includegraphics[scale=0.75]{liblinear-enron-avg-by-group_size}
	\caption{Accuracy of SVM OSB3 for the Enron E-mail Corpus}
	\label{fig:plot-liblinear-enron-accuracy}
\end{figure}
	
	\paragraph*{}It is important to note that there is no feature-author pairs limit issue for combinations using naive Bayes as a classification method.  However, SVM outperforms naive Bayes in these tests, so a careful analysis of SVM using the plots in Appendix Q through Appendix T is required.

	\paragraph*{} By examining the plots in Appendix Q through Appendix T, a clear trend emerges that the bootstrapped models, meaning models that made no use of the Web1T corpus as a vocabulary) performed similarly for SVM that did use Web1T vocabularies.  In all cases, the bootstrapped SVM tests are usable for all group sizes.  In this case, a good comparison would be to drop all SVM combinations that are not usable for all group sizes, then compare these remaining SVM tests against all naive Bayes tests.  Since all naive Bayes tests were usable for all group sizes, this makes the comparison fair.
	
	\paragraph*{} After removing SVM tests that were not usable against all groups sizes from consideration, the highest accuracy method-feature combinations for the Enron E-mail Corpus are higher in Table \ref{tab:enron-accuracy-filtered-ranked}.  The highest accuracy method-feature combination show the most accurate results for the Twitter Short Message Corpus in Table \ref{tab:twitter-accuracy-filtered-ranked}.
	
	
	\begin{table}[htbp!]
			\begin{center}
			\begin{tabular}{ | r | r | r | r | r | r | r | }
			\hline
			\multicolumn{2}{|c|}{Combinations} & \multicolumn{5}{|c|}{Accuracy}\\
			\hline
			Method & Feature Type & Web1T \% & AVG & MIN & MAX & STDDEV\\ \hline 
			SVM & OSB3 & 0 & 0.8362 & 0.5106 & 0.9732 & 0.1043\\ \hline 
			NB & OSB3 & 16 & 0.8325 & 0.5213 & 0.9823 & 0.0890\\ \hline 
			NB & OSB3 & 8 & 0.8315 & 0.5213 & 0.9714 & 0.0893\\ \hline 
			NB & OSB3 & 4 & 0.8274 & 0.5197 & 0.9587 & 0.0924\\ \hline 
			SVM & GM2 & 0 & 0.8262 & 0.4824 & 0.9753 & 0.1087\\ \hline 
			SVM & GB3 & 0 & 0.8212 & 0.4787 & 0.9835 & 0.1121\\ \hline 
			NB & GB3 & 16 & 0.8195 & 0.5201 & 0.9674 & 0.0947\\ \hline 
			NB & GB3 & 4 & 0.8194 & 0.5340 & 0.9522 & 0.0941\\ \hline 
			SVM & GB3 & 1 & 0.8191 & 0.4731 & 0.9673 & 0.1110\\ \hline 
			SVM & GB3 & 2 & 0.8184 & 0.4765 & 0.9805 & 0.1113\\ \hline 
			NB & GB3 & 8 & 0.8172 & 0.5255 & 0.9782 & 0.0935\\ \hline 
			NB & OSB3 & 1 & 0.8126 & 0.3615 & 0.9574 & 0.1185\\ \hline 
			NB & OSB3 & 2 & 0.8095 & 0.3526 & 0.9575 & 0.1283\\ \hline 
			NB & OSB3 & 0 & 0.8058 & 0.5185 & 0.9592 & 0.0970\\ \hline 
			SVM & GM5 & 16 & 0.7918 & 0.3908 & 0.9676 & 0.1204\\ \hline 
			SVM & GM5 & 8 & 0.7872 & 0.3908 & 0.9513 & 0.1193\\ \hline 
			NB & GB3 & 2 & 0.7857 & 0.4790 & 0.9669 & 0.1166\\ \hline 
			SVM & GM5 & 4 & 0.7755 & 0.3908 & 0.9455 & 0.1241\\ \hline 
			SVM & GM1 & 4 & 0.7742 & 0.4006 & 0.9590 & 0.1212\\ \hline 
			SVM & GM1 & 8 & 0.7740 & 0.4074 & 0.9570 & 0.1223\\ \hline 
			SVM & GM1 & 0 & 0.7735 & 0.3776 & 0.9531 & 0.1222\\ \hline 

			\end{tabular}
		\caption{Highest Accuracy Method-Feature Type Combinations for the Enron E-mail Corpus}
		\label{tab:enron-accuracy-filtered-ranked}
		\end{center}
	\end{table}
	

	
	\begin{table}[htbp!]
	\begin{center}
			\begin{tabular}{ | r | r | r | r | r | r | r | }
			\hline
			\multicolumn{2}{|c|}{Combinations} & \multicolumn{5}{|c|}{Accuracy}\\
			\hline
			Method	& Feature Type 	& Web1T \%	& AVG 		& MIN		& MAX		& STDDEV\\ \hline 
			NB	& OSB3		& 0		& 0.5525	& 0.2320	& 0.8164	& 0.1339\\ \hline 
			SVM	& GM2		& 16		& 0.5524	& 0.2419	& 0.8544	& 0.1270\\ \hline 
			SVM	& OSB3		& 16		& 0.5405	& 0.3704	& 0.7773	& 0.0788\\ \hline 
			SVM	& GM5		& 8		& 0.5343	& 0.3375	& 0.7827	& 0.0970\\ \hline 
			NB	& GB3		& 16		& 0.5327	& 0.2216	& 0.8216	& 0.1351\\ \hline 
			SVM	& GM5		& 16		& 0.5312	& 0.2951	& 0.8039	& 0.1048\\ \hline 
			NB	& GB3		& 4		& 0.5271	& 0.2190	& 0.8546	& 0.1375\\ \hline 
			SVM	& GM2		& 8		& 0.5264	& 0.1843	& 0.8489	& 0.1422\\ \hline 
			NB	& GB3		& 8		& 0.5256	& 0.2176	& 0.8474	& 0.1362\\ \hline 
			NB	& GB3		& 2		& 0.5249	& 0.2186	& 0.7823	& 0.1324\\ \hline 
			SVM	& GM2		& 4		& 0.5228	& 0.1809	& 0.8210	& 0.1477\\ \hline 
			NB	& GB3		& 1		& 0.5204	& 0.2148	& 0.8125	& 0.1319\\ \hline 
			NB	& GB3		& 0		& 0.5203	& 0.1973	& 0.8021	& 0.1389\\ \hline 
			SVM	& GM2		& 1		& 0.5197	& 0.1882	& 0.8454	& 0.1483\\ \hline 
			SVM	& GM1		& 8		& 0.5187	& 0.1743	& 0.9026	& 0.1525\\ \hline 
			SVM	& GM2		& 2		& 0.5186	& 0.1830	& 0.8232	& 0.1495\\ \hline 
			SVM	& GM1		& 1		& 0.5159	& 0.1768	& 0.8211	& 0.1494\\ \hline 
			SVM	& GM1		& 4		& 0.5149	& 0.1874	& 0.8546	& 0.1485\\ \hline 
			SVM	& GM1		& 0		& 0.5141	& 0.1802	& 0.8089	& 0.1485\\ \hline 
			NB	& GM1		& 0		& 0.5140	& 0.1247	& 0.7714	& 0.1631\\ \hline  

			\end{tabular}
		\caption{Highest Accuracy Method-Feature Type Combinations for the Twitter Short Message Corpus}
		\label{tab:twitter-accuracy-filtered-ranked}
		\end{center}	
	\end{table}
	
	
	\paragraph*{} From Table \ref{tab:enron-accuracy-filtered-ranked}, orthogonal sparse bigrams and gappy bigrams perform very well overall, with a traditional bigram making an entry at number five.  The best performing method-feature combination is SVM OSB3 with a Web1T\% of 0.  The next three combinations are naive Bayes classifiers using OSB3 with large Web1T\% vocabulary sizes.  The results are similar for gappy bigrams, but at a reduced accuracy of approximately one percent.
	
	\paragraph*{} From Table \ref{tab:twitter-accuracy-filtered-ranked}, the top performing method-feature combination is naive Bayes OSB3 with a Web1T \% of 0.  The next four positions are filled with gappy bigrams with sizable Web1T\% vocabularies.  Why Twitter responds better to naive Bayes as opposed to e-mail responding better to SVM is left to future work.
	
	\paragraph*{} While the Tables \ref{tab:enron-accuracy-filtered-ranked} and \ref{tab:twitter-accuracy-filtered-ranked} show the best performing combinations in terms of accuracy, accuracy is not always a solid measure of classification effectiveness.  A better measure is f-score.  As shown repeatedly by the tables in Appendix A through Appendix D, the relative performance of average f-score matched the relative performance of accuracy for each test set.  In all cases, f-score was lower than the average accuracy.  Even more telling about the results is every test set shows a minimum f-score of 0.  That means that at least one author had an f-score of zero in each test.  This accounts for the high standard deviation for f-scores across all tests.  For f-scores of approximately 0.65 the standard deviation was approximately 0.25.
	
	\paragraph*{} An examination of the confusion matrices for each test can provide insight into whether there was a "poison" author that never got selected or if there was an author who was a selection "magnet" being selected a disproportionately large number of times.  Due to the large number of confusions matrices in this thesis ( nearly 19,782 confusion matrices created from 57 tests * 3 size groupings * 6 vocabulary sizes * 5 feature types * 2 corpora * 2 methods -  738 unusable SVM tests) the confusions matrices are not presented, but are archived by the NPS Natural Language Processing lab in comma separated value files.

\paragraph*{} Another accuracy question is whether these method-feature combinations are stable performers across the group sizes.  While standard deviation is one indicator, a plot of the accuracy, f-score, and MLE for each of these choices would be informative for consistent performance across group sizes.  These plots can be compared to other method-feature combinations that have similar accuracy and size values.

\paragraph*{} Figure \ref{fig:accuracy-liblinear-enron-GM1-over-groups} shows that SVM GM1 has a steady decline from just above 80\% to 60\% from a groups size of 5 to a group size of 75.  The accuracy for SVM GM1 for the Enron corpus is virtually identical for groups sizes of 75 and 150. Figure \ref{fig:accuracy-liblinear-twitter-OSB3-over-groups} shows that SVM OSB3 for Twitter has declining accuracy from just above 60\% to slightly above 20\% as group size increases from 5 authors to 150 authors.  

\begin{figure}[htbp!]
	\begin{center}
	\centering
	\includegraphics[scale=0.5]{plot-accuracy-liblinear-enron-GM1}
	\caption{Accuracy Results over Group Size Using SVM GM1 for the Enron E-mail Corpus}
	\label{fig:accuracy-liblinear-enron-GM1-over-groups}
	\end{center}
\end{figure}

\begin{figure}[htbp!]
	\begin{center}
	\centering
	\includegraphics[scale=0.5]{plot-accuracy-nb-twitter-GB3}
	\caption{Accuracy Results over Group Size Using SVM OSB3 for the Twitter Short Message Corpus}
	\label{fig:accuracy-liblinear-twitter-OSB3-over-groups}
	\end{center}
\end{figure}

\paragraph*{} The results for author detection over the Enron E-mail Corpus are far higher than for the Twitter Short Message Corpus for the selected method-feature combinations.  This is not unexpected since results for the Enron E-mail Corpus have been higher than the Twitter Short Message Corpus across all test sets.  With both selections having storage requirements of less than 1MB, execution of actual author detection on a mobile phone is practical as a next stage in future work.

\begin{singlespace}
\section{Impact of Author Relative Prolificity on Classifier Effectiveness}
\end{singlespace}
	\paragraph*{} While identifying the highest accuracy for method-feature combinations is important, these results could mask a weakness in the method-feature combinations.  Does the relative prolificity of each author impact the results?  To answer this question, the tests in this thesis were conducted in three groupings: small-to-large, small-and-large, and random.  As explained fully in Chapter 3, these groupings were based on a rank-ordering by size for each author's total document collection.  For small-to-large, the least prolific authors are grouped together, while the most prolific authors are grouped together. The idea behind the small-to-large group is to keep the difference in total document size between the authors to a minimum. For small-and-large, the opposite idea is employed.  The smallest authors are combined with the largest authors using a bucket strategy.  Each bucket contains rank-ordered by size authors of similar size.  One author is picked from each bucket to provide a maximum variety of author document collections sizes.  In the random group, the authors are grouped together using a pseudo-random number generator, where each author has been assigned a number.
	\paragraph*{} The results of testing in this thesis for accuracy and f-score, broken out by small-to-large, small-and-large, and random are given in Appendix E through Appendix H.  The results from Appendix E, SVM Results for the Enron E-mail Corpus, show that the accuracy for small-to-large is always lower than for small-and-large and random.  However, the f-score for small-to-large is always higher than the f-score for small-and-large and random.  This result shows how accuracy is dominated by the MLE author, since allowing a more prolific author into a group with less prolific authors tends to raise accuracy, but hurts f-score. To illustrate the effect of author prolificity on accuracy and f-score Table \ref{tab:enron-stl-confusionmatrix} shows the confusion matrix for a small-to-large grouping of size 10 for GB3, Web1T\%=0.  Table \ref{tab:enron-sal-confusionmatrix} shows the confusion matrix for a small-and-large grouping of size 10 for GB3, Web1T\%=0. 
	
	\begin{table}[htbp!]
	\begin{center}
			\begin{tabular}{ | c | r | r | r | r | r | r | r | r | r| r | r |}
			\cline{3-12}
			\multicolumn{2}{c}{} & \multicolumn{10}{|c|}{Label}\\ \cline{3-12}
			\multicolumn{2}{c|}{} & 11 & 111 & 119 & 14 & 146 & 15 & 48 & 60 & 71 & 91\\ \hline 
			\multirow{10}{*}{\begin{sideways}Truth\end{sideways}} & 11 & 0 & 0 & 0 & 0 & 0 & 0 & 2 & 0 & 1 & 0\\ \cline{2-12}
			& 111 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ \cline{2-12} 
			& 119 & 0 & 0 & 8 & 1 & 0 & 0 & 0 & 0 & 0 & 6\\ \cline{2-12} 
			& 14 & 0 & 0 & 0 & 4 & 0 & 0 & 0 & 0 & 0 & 10\\ \cline{2-12} 
			& 146 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 1\\ \cline{2-12} 
			& 15 & 0 & 0 & 0 & 1 & 0 & 4 & 1 & 0 & 0 & 4\\ \cline{2-12} 
			& 48 & 0 & 0 & 0 & 2 & 0 & 0 & 9 & 0 & 0 & 2\\ \cline{2-12} 
			& 60 & 0 & 0 & 2 & 0 & 0 & 0 & 1 & 4 & 0 & 2\\ \cline{2-12} 
			& 71 & 0 & 0 & 0 & 2 & 0 & 0 & 0 & 0 & 0 & 4\\ \cline{2-12} 
			& 91 & 0 & 0 & 0 & 2 & 0 & 0 & 1 & 0 & 0 & 17\\ \hline
	\end{tabular}
		\caption{Confusion Matrix for Small-To-Large Grouping, Feature Type: GB3, Group Size: 10, Web1T\%: 0}
		\label{tab:enron-stl-confusionmatrix}
		\end{center}	
	\end{table}
	
	\begin{table}[htbp!]
	\begin{center}
			\begin{tabular}{ | c | r | r | r | r | r | r | r | r | r| r | r |}
			\cline{3-12}
			\multicolumn{2}{c}{} & \multicolumn{10}{|c|}{Label}\\ \cline{3-12}
			\multicolumn{2}{c|}{} & 11 & 113 & 47 & 49 & 58 & 75 & 76 & 86 & 88 & 95\\ \hline 
			\multirow{10}{*}{\begin{sideways}Truth\end{sideways}}& 11 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 2 & 0\\ \cline{2-12} 
			& 113 & 0 & 203 & 43 & 23 & 3 & 6 & 0 & 4 & 19 & 0\\ \cline{2-12} 
			& 47 & 0 & 7 & 2510 & 2 & 4 & 2 & 0 & 3 & 61 & 0\\ \cline{2-12}
			& 49 & 0 & 16 & 52 & 1180 & 2 & 6 & 0 & 2 & 48 & 1\\ \cline{2-12} 
			& 58 & 0 & 1 & 16 & 2 & 508 & 0 & 0 & 0 & 7 & 0\\ \cline{2-12} 
			& 75 & 0 & 5 & 19 & 4 & 0 & 338 & 0 & 1 & 16 & 0\\ \cline{2-12} 
			& 76 & 0 & 0 & 1 & 3 & 0 & 0 & 9 & 0 & 1 & 0\\ \cline{2-12} 
			& 86 & 0 & 14 & 12 & 14 & 2 & 9 & 0 & 36 & 15 & 0\\ \cline{2-12} 
			& 88 & 0 & 11 & 129 & 12 & 1 & 7 & 0 & 0 & 277 & 1\\ \cline{2-12} 
			& 95 & 0 & 4 & 2 & 7 & 3 & 2 & 0 & 1 & 9 & 4\\ \hline
	\end{tabular}
		\caption{Confusion Matrix for Small-And-Large Grouping, Feature Type: GB3, Group Size: 10, Web1T\%: 0}
		\label{tab:enron-sal-confusionmatrix}
		\end{center}	
	\end{table}
	
	\paragraph*{} Table \ref{tab:enron-stl-confusionmatrix} represents a group of similarly prolific authors.  One author, author 91, not only has the highest number of true positives, 17, but has a large number of false positives.  The combined false positives for all other authors is 21, compared to author 91's 29 false positives.  That counts as 29 false negatives spread across the other 9 authors, impacting their false negative value.  For calculating f-score, a higher false negative rate decreases recall and, since true positives remain constant, false positives fall, increasing precision.  In the small-to-large grouping, one author has very few false positives, creating a high precision.  The other authors end up with a high recall.  As the f-score for each author is average for the group, these unbalanced numbers drive the f-score higher while maintaining a lower accuracy.
	\paragraph*{} Table \ref{tab:enron-sal-confusionmatrix} represents a group of dissimilarly prolific authors.  In this grouping, one author does not dominate the number of false positives.  This more evenly spread set of false positives and false negatives keeps the overall f-score lower, while maintaining a higher accuracy.  High outlier precision score for one author in the small-to-large group gives a higher f-score, but lower accuracy.  A median measurement of f-score might provide a better picture of overall f-score behavior than an average f-score.  We provide CDFs to investigate further in Section 4.2.1 and in Appendix U through Appendix X.
	\paragraph*{} The other issue that arises from the f-score average is the small-to-large f-score has a smaller standard deviation than the small-and-large f-score.  This points to a tighter grouping of values.  This arises from all but one author having similar f-score values.  The small-and-large group has no single outlier f-score to drag the f-score higher, but the values do have greater variation among all points.
	\paragraph*{}Our analysis represents a cursory examination of the behavior of author detection due to author prolificity.  An in-depth statistical analysis of the difference between the author groupings is warranted as future work.  The goal of using these different groupings was to ensure that the tools chosen in this thesis behaved predictably with respect to varying author prolificity within a detection group.  To examine that behavior, plots of accuracy, average f-score, MLE, precision, and recall for each method-feature combination across all usable Web1T\% vocabularies is included in Appendix Q through Appendix U.  To illustrate that the impact of author prolificity is predictable across method-feature combinations and corpora, Figure \ref{fig:liblinear-enron-GB3-10-measures} and Figure \ref{fig:liblinear-twitter-GB3-10-measures} are shown as representative samples of overall classifier and corpora results.
	
\begin{figure}[htbp!]
	\begin{center}
	\centering
	\includegraphics[scale=0.95]{figure_liblinear_enron_grouping_compare}
	\caption{SVM Limits Due to Vocabulary Size and Group Size for the Enron E-mail Corpus.  The X-axis shows the filenames for each test, not a range of numbers.  For Small-To-Large, the file 000\_009 holds the least prolific authors.  The file 140\_149 holds the most prolific authors.  For small-and-large, each file holds a collection of dissimilarly prolific authors.}
	\label{fig:liblinear-enron-GB3-10-measures}
	\end{center}
\end{figure}

\begin{figure}[htbp!]
	\begin{center}
	\centering
	\includegraphics[scale=0.95]{figure_liblinear_twitter_grouping_compare}
	\caption{SVM Limits Due to Vocabulary Size and Group Size for the NPS Twitter Short Message Corpus. The X-axis shows the filenames for each test, not a range of numbers.  For Small-To-Large, the file 000\_009 holds the least prolific authors.  The file 140\_149 holds the most prolific authors.  For small-and-large, each file holds a collection of dissimilarly prolific authors.}
	\label{fig:liblinear-twitter-GB3-10-measures}
	\end{center}
\end{figure}
	
	
	In Figures \ref{fig:liblinear-enron-GB3-10-measures} and \ref{fig:liblinear-twitter-GB3-10-measures}, the X-axis shows the filenames for each test, not a range of numbers.  For Small-To-Large, the file 000\_009 holds the least prolific authors.  The file 140\_149 holds the most prolific authors.  For small-and-large, each file holds a collection of dissimilarly prolific authors.
	\paragraph*{} From Figure \ref{fig:liblinear-enron-GB3-10-measures} some trends become apparent.  As the small-to-large graph for the Enron corpus, Figure \ref{fig:liblinear-enron-GB3-10-measures}c moves from left to right, the accuracy, f-score, precision, and recall all increase in tight agreement.  This correlates to the wide variation in prolificity between the least prolific group on the far left, file 000\_009, and the last file on the far right, file 140\_149.  In the Enron corpus, the least prolific author's document total size is a few kilobytes where the most prolific author's document total size is measured in megabytes.  Most striking is that the trend holds for both SVM and naive Bayes.  Also, with a group size of 10, the most prolific authors have a high accuracy, high f-score, high precision, and high recall.  The impact of prolificity is predictable and significant for the Enron Corpus.
	\paragraph*{} The results for the Enron corpus small-and-large group are largely flat as the graph moves from left to right.  This shows that in a mixed group of varying prolificity, both SVM and naive Bayes maintain fairly consistent results.  Clearly, having an author who is significantly more prolific than other authors in his detection group hurts the average f-score for that group while raising the accuracy.  This rise in accuracy is not a good indicator of improved performance.  For the Enron E-mail Corpus, prolific authors are more detectable than less prolific authors, even in the presence of other prolific authors.
	
	\paragraph*{} In Figure \ref{fig:liblinear-enron-GB3-10-measures} panels (a) and (b) (the Enron small-and-large graphs) precision and accuracy are close in value where f-score and recall are always close in value.  The accuracy and precision values are also always above the f-score and recall values.  Investigation into the underlying reasons for this pattern warrants future work in an in-depth statistical analysis of the effects of grouping on author detection.
	\paragraph*{} In Figure \ref{fig:liblinear-twitter-GB3-10-measures} panels (a) and (b) (the Twitter small-and-large graphs) precision, recall, accuracy, and f-score do no show the same clear trends as Enron. Precision, recall, accuracy, and f-score are lower for the Twitter Short Message Corpus than for the Enron E-mail Corpus. The highest graphed value in Figure \ref{fig:liblinear-twitter-GB3-10-measures} is 0.7 compared to Enron's highest graphed value of 1.0 in Figure \ref{fig:liblinear-enron-GB3-10-measures}.  The relative flatness of measures in the Twitter corpus compared to the Enron corpus can be explained by the difference in relative sizes of an author's tweets in the Twitter corpus and an author's e-mails in the Enron corpus.  The most prolific author in the Twitter corpus has only 15.2KB of text as opposed to 2.5MB for the most prolific Enron author.  Gathering a larger Twitter corpus of original, not re-tweeted, short messages could supply a similar size and variation of the Enron corpus. Such a compilation of Twitter text is recommended for future work.
	
	\subsection{Cumulative Distribution of Authors Over F-Scores Due to Grouping}
	\paragraph*{} To further illustrate the impact of grouping similarly prolific, dissimilarly prolific, and randomly prolific authors together, cumulative distribution graphs were constructed for four scenarios: SVM for Enron in Figure \ref{fig:plot-tiled-cdf-summary-liblinear-enron-gb3-10}, naive Bayes for Enron in Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-gb3-10}, SVM for Twitter in Figure \ref{fig:plot-tiled-cdf-summary-liblinear-twitter-gb3-10}, and naive Bayes for Twitter in Figure \ref{fig:plot-tiled-cdf-summary-nb-twitter-gb3-10}.  Each graph is displayed as one of six panels, all tiled in one figure.  Each panel represents a different Web1T\% value for that method-corpus combination.  The Web1T\% values for each panel are, from upper left to lower right by row, 0, 1, 2, 4, 8, and 16.  
	\paragraph*{}Each panel has three curves plotted as the cumulative distribution of author's f-score.  The f-scores in these panels are per-author. These per-author f-scores are not averaged over author and are not weighted in any way.  For the sake of consistent presentation, all four figures use GB3 as the feature type and a group size of 10.  The graphs shown are representative of all feature types (GM1, GM2, GM5, GB3, OSB3) as shown in Appendix U through Appendix X. There is one blank graph in Figures \ref{fig:plot-tiled-cdf-summary-liblinear-enron-gb3-10} and \ref{fig:plot-tiled-cdf-summary-liblinear-twitter-gb3-10}.  The blank graph occurs when the number of authors coupled with the number of types exceeds $2^{31}$ elements and cannot fit into the array used by the libLinear model as described in Section 3.2.2 and Section 4.1.
	
	\paragraph*{} The characteristics being examined in these cumulative distribution graphs are: the curvature within the graph, how closely the curves are grouped, and the left/right position of the curves.  
	\begin{itemize}
		\item For curvature, down and right curvatures shows that a larger number of authors have higher f-scores (e.g. more of the probability mass is contained in high scores). Down and right curvature means more authors experience better classifier performance. A curve with up and left curvature shows that a larger number of authors have lower f-scores.  Up and left curvature indicates poorer classifier performance.
		\item For inter-CDF similarity, more closely grouped curves indicate a smaller author prolificity effect on f-score.  For instance, if the small-to-large curve, representing similarly prolific authors, has down and right curvature while the small-and-large, representing dissimilarly prolific authors, has up and left curvature, there is a clear indication that author prolificity affects the classifier.  More closely grouped curves demonstrate more consistent classifier performance across grouping strategies.
		\item In examining the left/right position of curves, curves positioned further to the right indicate more authors with a higher f-score. For instance, a line starting with an f-score of 0.0 shows that at least one author had a f-score of 0.0.  A line starting at 0.4 shows the worst f-score for any author was 0.4.  Curves with positions further to the right demonstrate a better performing method-feature combination.
	\end{itemize}
	
	\paragraph*{} There are several overall findings from the cumulative distribution analysis of f-score for different Web1T\% values:
	\begin{itemize}
	\item SVM performs better for the Enron E-mail Corpus than naive Bayes
	\item Overall, groups of similarly prolific authors perform the same or slightly better than groups of dissimilarly prolific authors.
	\item Except for naive Bayes in the Enron E-mail Corpus, Web1T provides little improvement to classifier performance.
	\item Naive Bayes for the Enron E-mail Corpus has better performance for Web1T\% of 1 and than Web1T\% of 0, but increasing Web1T\% above 1 provides no additional performance improvement.
	\item Author detection in Twitter accuracy is almost identical for SVM and naive Bayes.
	\end{itemize}
	
	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-liblinear-enron-gb3-10-crop}
		\caption{Graphs of the Cumulative Distribution of Authors Over F-Score for the Enron E-mail Corpus using SVM. Each panel in this figure shows SVM using GB3 for the Enron E-mail Corpus.  Each panel represents a different Web1T\% value.  From top-left to bottom-right, those Web1T\% values are 0, 1, 2, 4, 8, and 16.  The blank graph in the sixth panel represents an author-feature pairing that was too large for libLinear to execute as described in Section 3.2.2 and Section 4.1.  The curves in each graph are: Small-To-Large (STL), Small-And-Large (SAL), and Random (RAN).  STL represents groups of similarly prolific authors.  SAL represents groups of dissimilarly prolific authors.  RAN represents authors of random prolificity grouped together.  Curves with down and right curvature indicate better performance that curves with up and left curvature.  Curves positioned further to the right indicate better performance that curves positioned further to the left.  Curves with tighter grouping indicate more consistent performance than curves with looser grouping.}
		\label{fig:plot-tiled-cdf-summary-liblinear-enron-gb3-10}
		\end{center}
	\end{figure}
	
	\paragraph*{}  
	\begin{itemize}
	\item Web1T\% has little impact on SVM performance for the Enron E-mail Corpus.
	\end{itemize}
	\paragraph*{Curvature}The panels in Figure \ref{fig:plot-tiled-cdf-summary-liblinear-enron-gb3-10} show a representative set of curves for all SVM tests on the Enron E-Mail Corpus.  Looking at the first panel of Figure \ref{fig:plot-tiled-cdf-summary-liblinear-enron-gb3-10}, Web1T\% of 0, all three lines, small-to-large, small-and-large, and random have similar curvature.  That curvature is down and right. The small-to-large curve slightly outperforms the small-and-large and random curves up to an f-score of 0.7. This similarity in curvature is consistent as the Web1T\% increases through the next five panels: Web1T\% of 1, 2, 4, 8, and 16. 
	\paragraph*{Grouping}All three curves are grouped closely together.  The close grouping is also consistent through the next five panels. This demonstrates that relative author prolificity within a group has little impact when SVM is used on the Enron E-mail Corpus.
	\paragraph*{Position}The left to right positioning of the curves is nearly identical.  This positioning is consistent through the next five panels.
	\paragraph*{Impact} These panels show that SVM on Enron performs consistently and generally positively across Web1T\% values.  This indicates that the Web1T, as a vocabulary, is not very helpful in improving SVM performance on the Enron Email Corpus. These panels also show that SVM performance against Enron is consistent for both similarly and dissimilarly prolific authors.
	
	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.6]{plot-tiled-cdf-summary-nb-enron-gb3-10-crop}
		\caption{Graphs of the Cumulative Distribution of Authors Over F-Score for the Enron E-mail Corpus using Naive Bayes. Each panel in this figure shows naive Bayes using GB3 for the Enron E-mail Corpus.  Each panel represents a different Web1T\% value.  From top-left to bottom-right, those Web1T\% values are 0, 1, 2, 4, 8, and 16.  The curves in each graph are: Small-To-Large (STL), Small-And-Large (SAL), and Random (RAN).  STL represents groups of similarly prolific authors.  SAL represents groups of dissimilarly prolific authors.  RAN represents authors of random prolificity grouped together.  Curves with down and right curvature indicate better performance that curves with up and left curvature.  Curves positioned further to the right indicate better performance that curves positioned further to the left.  Curves with tighter grouping indicate more consistent performance than curves with looser grouping.}
		\label{fig:plot-tiled-cdf-summary-nb-enron-gb3-10}
		\end{center}
	\end{figure}
	
	\paragraph*{}
	\begin{itemize}
	\item Dissimilarly prolific authors perform significantly better with Web1T used in naive Bayes for the Enron Corpus
	\end{itemize}
	\paragraph*{Curvature}The panels in Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-gb3-10} show a representative set of curves for all naive Bayes tests on the Enron E-mail Corpus.  Looking at the first panel of Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-gb3-10}, Web1T\% of 0, the curvature of the small-to-large curve (similarly prolific authors) is down and right.  The small-and-large curve (dissimilarly prolific authors) and the random curve have up and left curvature.  This indicates that the majority of similarly prolific authors are classified significantly better than dissimilarly prolific authors when using naive Bayes for the Enron E-mail Corpus with a Web1T\% of 0.  This pattern is not consistent moving to the second panel, Web1T\% of 1.  In the second panel, the small-and-large curve and the random curve  both have down and right curvature.  
	\paragraph*{Grouping}In the first panel, Web1T\% of 0, the curves are not tightly grouped. In the second panel, Web1T\% of 1, all three curves are grouped closer together, but not as closely as in SVM for Enron (Figure \ref{fig:plot-tiled-cdf-summary-liblinear-enron-gb3-10}).  The grouping varies slightly through the next four panels with the small-to-large curve always outperforming small-and-large and random curves. 
	\paragraph*{Position}The left to right positioning of the all three curves is nearly identical for the second through sixth panels (Web1T\% of 1, 2, 4, 8, and 16).  The position of the small-and-large curve and the random curve improved from the first panel, Web1T\% of 0, to the second panel, Web1T\% of 1.  This is another indication that increasing Web1T\%  beyond 1 does not significantly help performance.
	\paragraph*{Impact} There are three observations from the naive Bayes for Enron panels in Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-gb3-10}:
	\begin{itemize}
	\item First, moving from a bootstrap naive Bayes using Laplace plus one smoothing to a Laplace Web1T\% smoothing greatly improves the performance of the dissimilarly prolific authors without any appreciable change to the performance of similarly prolific authors.  This demonstrates that Web1T\% is useful as a smoothing tool for naive Bayes in the Enron E-mail corpus.  
	\item Second, there is no further significant performance improvement to any curve as the Web1T\% increases beyond 1\%.  This demonstrates that only the most common terms in the Web1T corpus have a significant impact on naive Bayes performance. This supports our hypothesis regarding Zipf's Law.  We hypothesized that the most frequently occurring tokens in the Web1T corpus increase classifier performance more than less frequently occurring tokens.  For this case, naive Bayes in the Enron Email Corpus, there is a significant performance increase from Web1T\% of 0 to Web1T\% of 1.  There is little performance improvement for Web1T\% greater than 1.  This indicates that the top 1\% of the Web1T corpus is improving naive Bayes performance the most.
	\item Third, using naive Bayes, f-score performs similarly for small-to-large with Web1T or without Web1T.  This demonstrates that naive Bayes performs the same for similarly prolific authors regardless of the use of Web1T. 
	\end{itemize}
	
	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-liblinear-twitter-gb3-10-crop}
		\caption{Graphs of the Cumulative Distribution of Authors Over F-Score for the NPS Twitter Short Message Corpus using SVM. Each panel in this figure shows SVM using GB3 for the Enron E-mail Corpus.  Each panel represents a different Web1T\% value.  From top-left to bottom-right, those Web1T\% values are 0, 1, 2, 4, 8, and 16.  The blank graph in the sixth panel represents a author-feature pairing that was too large for libLinear to execute as described in Section 3.2.2 and Section 4.1.  The curves in each graph are: Small-To-Large (STL), Small-And-Large (SAL), and Random (RAN).  STL represents groups of similarly prolific authors.  SAL represents groups of dissimilarly prolific authors.  RAN represents authors of random prolificity grouped together.  Curves with down and right curvature indicate better performance that curves with up and left curvature.  Curves positioned further to the right indicate better performance that curves positioned further to the left.  Curves with tighter grouping indicate more consistent performance than curves with looser grouping.}
		\label{fig:plot-tiled-cdf-summary-liblinear-twitter-gb3-10}
		\end{center}
	\end{figure}
	
	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-nb-twitter-gb3-10-crop}
		\caption{Graphs of the Cumulative Distribution of Authors Over F-Score for the NPS Twitter Short Message Corpus using Naive Bayes. Each panel in this figure shows naive Bayes using GB3 for the Enron E-mail Corpus.  Each panel represents a different Web1T\% value.  From top-left to bottom-right, those Web1T\% values are 0, 1, 2, 4, 8, and 16.  The curves in each graph are: Small-To-Large (STL), Small-And-Large (SAL), and Random (RAN).  STL represents groups of similarly prolific authors.  SAL represents groups of dissimilarly prolific authors.  RAN represents authors of random prolificity grouped together.  Curves with down and right curvature indicate better performance that curves with up and left curvature.  Curves positioned further to the right indicate better performance that curves positioned further to the left.  Curves with tighter grouping indicate more consistent performance than curves with looser grouping.}
		\label{fig:plot-tiled-cdf-summary-nb-twitter-gb3-10}
		\end{center}
	\end{figure}
	
	\begin{itemize}
	\item Both SVM and naive Bayes produce nearly identical, mediocre results for the Twitter Short Message Corpus
	\end{itemize}
	
		\paragraph*{Curvature}  The panels in Figure \ref{fig:plot-tiled-cdf-summary-liblinear-twitter-gb3-10} show a representative set of curves for all SVM tests on the Twitter Short Message Corpus.  The panels in Figure \ref{fig:plot-tiled-cdf-summary-nb-twitter-gb3-10} show a representative set of curves for all naive Bayes tests on the Twitter Short Message Corpus. Both figures are nearly identical.  Looking at the first panel, Web1T\% of 0, of both figures, all three curves, small-to-large (similarly prolific authors), small-and-large (dissimilarly prolific authors), and random are all have similar curvature.  That curvature is an ``S" shape. The ``S" shape indicates that there are few authors with low f-scores and few authors with high f-scores. This suggests the same, small, number of authors perform well for small-to-large as in small-and-large while authors in the middle of the curve perform worse. No curve regularly outperforms the others. This similarity in curvature is consistent as the Web1T\% increases through the next five panels (Web1T of 1, 2, 4, 8, and 16). 
		\paragraph*{Grouping} All three curves are grouped closely together.  The close grouping is consistent through all six panels.  This shows that neither SVM nor naive Bayes is significantly impacted by similarly or dissimilarly prolific author grouping. 
		\paragraph*{Position} The left/right positioning of all three curves is nearly identical except that introducing a Web1T\% of 1 as the Laplace Smoothing values for naive Bayes (Figure \ref{fig:plot-tiled-cdf-summary-liblinear-twitter-gb3-10}) shifts the curves further to the right, improving overall performance.  This positioning does not shift as the Web1T\% increases.  This demonstrates that only the top 1\% of Web1T has a significant impact on naive Bayes and SVM performance in the Twitter Short Message Corpus.
		\paragraph*{Impact} These panels show that the results of SVM and naive Bayes on Twitter are consistent and generally mediocre with any or none of Web1T.  It also shows that SVM performance against Twitter is consistent for both similarly and dissimilarly prolific authors.

\subsection{Cumulative Distribution of Authors Over F-Score Due to Group Sizes}
\begin{comment}\paragraph*{} Figures \ref{fig:plot-tiled-cdf-summary-liblinear-enron-GB3-ALL-0}, \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0}, \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1}, \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1}, and \ref{fig:plot-tiled-cdf-summary-nb-twitter-GB3-ALL-0} all display the cumulative distribution of authors over f-score as group size is increased. There are six panels in each figure.  The panels progress from upper left to bottom right through group sizes 5, 10, 25, 50, 75, and 150.  To provide a consistent presentation, all of these figures except Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1} display a Web1T\% of 0 for feature type GB3. Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1} displays a Web1T\% of 1 for feature type GB3 to present the difference in curvature between naive Bayes against Enron for both Web1T\% of 0 (Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0}) and a Web1T\% of 1 (Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1}).
\end{comment}
	\paragraph*{} To further illustrate the impact of grouping similarly prolific, dissimilarly prolific, and randomly prolific authors together, cumulative distribution graphs were constructed for four scenarios: SVM for Enron in Figure \ref{fig:plot-tiled-cdf-summary-liblinear-enron-GB3-ALL-0}, naive Bayes for Enron in Figures \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0} and \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1}, SVM for Twitter in Figure \ref{fig:plot-tiled-cdf-summary-liblinear-twitter-GB3-ALL-0}, and naive Bayes for Twitter in Figure \ref{fig:plot-tiled-cdf-summary-nb-twitter-GB3-ALL-0}.  Each graph is displayed as one of six panels, all tiled in one figure.  Each panel represents a different group size for that method-corpus combination.  The group sizes for each panel are, from upper left to lower right by row, 5, 10, 25, 50, 75, and 150.  
	\paragraph*{}Each panel has three curves plotted as the cumulative distribution of authors over f-score.  The f-scores in these panels are per-author. These per-author f-scores are not averaged over author and are not weighted in any way.  For the sake of consistent presentation, all five figures use GB3 as the feature type and a Web1T\% of 0 (except for Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1}).  The graphs shown are representative of all feature types (GM1, GM2, GM5, GB3, OSB3) as shown in Appendix U through Appendix X. There is one blank graph in Figures \ref{fig:plot-tiled-cdf-summary-liblinear-enron-GB3-ALL-0} and \ref{fig:plot-tiled-cdf-summary-liblinear-twitter-GB3-ALL-0}.  The blank graph occurs when the number of authors coupled with the number of types exceeds $2^{31}$ elements and cannot fit into the array used by the libLinear model as described in Section 3.2.2 and Section 4.1.
	
\begin{comment}
	\paragraph*{} The characteristics being examined in these cumulative distribution graphs are: the curvature within the graph, how closely the curves are grouped, and the left/right position of the curves.  
	\begin{itemize}
		\item For curvature, down and right curvature shows that a larger number of authors have higher f-scores. down and right curvature means better classifier performance. Up and left curvature shows that a larger number of authors have lower f-scores.  Up and left curvature indicates poorer classifier performance.
		\item For close grouping of curves, more closely grouped curves indicate a smaller author prolificity effect on f-score.  For instance, if the small-to-large curve, representing similarly prolific authors, has down and right curvature while the small-and-large curve, representing similarly prolific authors, has up and left curvature, there is a clear indication that author prolificity affects the classifier.  More closely grouped curves demonstrate more consistent classifier performance.
		\item In examining the left/right position of curves, curves positioned further to the right indicate more authors with a higher f-score. For instance, a line starting with an f-score of 0.0 shows that at least one author had a f-score of 0.0.  A line starting at 0.4 shows the worst f-score for any author was 0.4.  Curves with positions further to the right demonstrate a better performing method-feature combination.	
	\end{itemize}
\end{comment}

	\paragraph*{} There are several overall findings from the cumulative distribution analysis of f-score for different author set sizes:
	\begin{itemize}
	\item SVM performs better for the Enron E-mail Corpus than naive Bayes
	\item Overall, groups of similarly prolific authors perform the same or slightly better than groups of dissimilarly prolific authors.
	\item As group size increases, overall performance worsens.
	\item As group size increases, the top and bottom performing authors maintain their f-scores while more average performing authors experience worse performance.
	\item Author detection in Twitter produces almost identical results for SVM and naive Bayes.
	\end{itemize}


	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-liblinear-enron-GB3-ALL-0-crop}
		\caption{Graphs of the Cumulative Distribution of Authors Over F-Score for the Enron E-mail Corpus using SVM. Each panel in this figure shows SVM using GB3 for the Enron E-mail Corpus.  Each panel represents a different group size.  From top-left to bottom-right, those group sizes are 5, 10, 25, 50, 75, and 150.  The blank graph in the sixth panel represents a author-feature pairing that was too large for libLinear to execute as described in Section 3.2.2 and Section 4.1.  The curves in each graph are: Small-To-Large (STL), Small-And-Large (SAL), and Random (RAN).  STL represents groups of similarly prolific authors.  SAL represents groups of dissimilarly prolific authors.  RAN represents authors of random prolificity grouped together.  Curves with down and right curvature indicate better performance that curves with up and left curvature.  Curves positioned further to the right indicate better performance that curves positioned further to the left.  Curves with tighter grouping indicate more consistent performance than curves with looser grouping.}
		\label{fig:plot-tiled-cdf-summary-liblinear-enron-GB3-ALL-0}
		\end{center}
	\end{figure}

\paragraph*{} 
	\begin{itemize}
	\item SVM performance is consistent and generally positive for similarly and dissimilarly prolific authors in the Enron E-mail Corpus.
	\end{itemize}
	\paragraph*{Curvature}Figure \ref{fig:plot-tiled-cdf-summary-liblinear-enron-GB3-ALL-0} shows the typical progression of curvature as group size increases from an initial value of 5 to a final value of 150.  All three curves, small-to-large (similarly prolific authors), small-and-large (dissimilarly prolific authors), and random, progress from a down and right curvature to an up and left curvature.  None of the feature-group size combination ever curve left and up past a basically straight, diagonal curve.  This indicates that increasing group size causes worse author detection performance.
	\paragraph*{Grouping} The grouping of the lines gets tighter as the group size increases.  Specifically, similarly prolific authors decrease performance at a faster rate as the group sizes increase, causing the small-to-large curve to decrease the distance between it and the small-and-large and random lines.  The tightened grouping shows that group size impacts the small-to-large line more than the small-and-large and random lines.  This makes intuitive sense because the larger group sizes makes the similarly prolific authors ``less similar."  When all 150 authors are included in the similarly prolific author group, there is no difference between the similarly and dissimilarly prolific authors.  
	\paragraph*{Position}The left to right position of the endpoints of all three curves remains relatively fixed through all group sizes.  This shows that the worst and best f-scores remain relatively constant through the group sizes while f-scores for average performing authors worsens.  
	\paragraph*{Impact} SVM performance in the Enron E-mail Corpus is consistent and generally positive for similarly and dissimilarly prolific authors.  Increasing group size worsens performance for both similarly and dissimilarly prolific author groups.
	
	
	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-nb-enron-GB3-ALL-0-crop}
		\caption{Graphs of the Cumulative Distribution of Authors Over F-Score for the Enron E-mail Corpus using Naive Bayes. Each panel in this figure shows naive Bayes using GB3 and a Web1T\% of 0 for the Enron E-mail Corpus.  Each panel represents a different group size.  From top-left to bottom-right, those group sizes are 5, 10, 25, 50, 75, and 150. The curves in each graph are: Small-To-Large (STL), Small-And-Large (SAL), and Random (RAN).  STL represents groups of similarly prolific authors.  SAL represents groups of dissimilarly prolific authors.  RAN represents authors of random prolificity grouped together.  Curves with down and right curvature indicate better performance that curves with up and left curvature.  Curves positioned further to the right indicate better performance that curves positioned further to the left.  Curves with tighter grouping indicate more consistent performance than curves with looser grouping.}
		\label{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0}
		\end{center}
	\end{figure}
\begin{comment}	
	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-nb-enron-GB3-ALL-1-crop}
		\caption{Graphs of the Cumulative Distribution of Authors Over F-Score for the Enron E-mail Corpus using Naive Bayes. Each panel in this figure shows naive Bayes using GB3 and a Web1T\% of 1 for the Enron E-mail Corpus.  Each panel represents a different group size.  From top-left to bottom-right, those group sizes are 5, 10, 25, 50, 75, and 150. The curves in each graph are: Small-To-Large (STL), Small-And-Large (SAL), and Random (RAN).  STL represents groups of similarly prolific authors.  SAL represents groups of dissimilarly prolific authors.  RAN represents authors of random prolificity grouped together.  Curves with down and right curvature indicate better performance that curves with up and left curvature.  Curves positioned further to the right indicate better performance that curves positioned further to the left.  Curves with tighter grouping indicate more consistent performance than curves with looser grouping.}
		\label{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1}
		\end{center}
	\end{figure}


\paragraph*{} 
\begin{itemize}
\item Naive Bayes for the Enron E-mail Corpus shows different performance progression as group size increases for Web1T\% of 0 and 1.
\end{itemize}
Figures \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0} and \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1} both show the cumulative distribution of authors over f-score for naive Bayes against Enron.  The two graphs start with different curvatures.  Both graphs get closer grouping and worsening performance for all author groups as group size increases.  However, similarly prolific author curves are more alike between Web1T\% of 1 than for Web1T\% of 0 than dissimilarly prolific author groups.  This is expected after the results from Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-gb3-10}. However, the group size of 150 for Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0} is essentially a straight, diagonal line whereas in Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1} the curves are up and left.  This indicates that naive Bayes benefits from the use of Web1T\% of 1 over naive Bayes with a Web1T\% of 0.  This result is typical of all the naive Bayes against Enron cumulative distribution graphs.  This begs the question of whether Web1T smoothing performs better than other smoothing techniques such as Witten-Bell or Good-Turing.  Witten-Bell and Good-Turing do not bring the large storage requirement of Web1T smoothing, but may produce similar results.  Determining this result is left for future work.
\end{comment}

\paragraph*{} 
\begin{itemize}
\item Increasing group size impacts similarly prolific author groups more than dissimilarly prolific author groups for naive Bayes using Web1T\% of 0 in the Enron E-mail Corpus.
\end{itemize}
\paragraph*{Curvature} Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0} shows the cumulative distribution of authors over f-scores for naive Bayes in Twitter.  The first panel of Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0} shows significant separation between similarly prolific and dissimilarly prolific author groups. The first panel of Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0}, group size of 5, starts with separation between the small-to-large curve (similarly prolific authors) and the small-and-large curve (dissimilarly prolific authors).  The small-to-large curvature is down and right where the small-and-large curvature is up and left.  This indicates better performance for similarly prolific authors than for dissimilarly prolific authors. 
\paragraph*{Grouping}As group size increases, the curvature of all lines increases, but not at the same rate.  The small-to-large curve closes the gap between curves until all curves are merged in the last panel, group size of 150.  (Note: It makes sense that the last panel shows all curves on top of each other because the same 150 authors are included in all three curves.  If these lines showed different curvature, that would indicate a problem with the methodology, since the only difference between the training and test sets of these three lines is the order that documents are read by the classifier.  For group sizes of 5 through 75, each line contains groups unique combinations of authors.)
\paragraph*{Position}The left/right position of the curves does not change significantly as group size increases while curvature did change.  This shows that increasing group size has less effect on the top and bottom performing authors than on the average performing authors.
\paragraph*{Impact} Naive Bayes without Web1T in the Enron E-mail corpus does not perform consistently between groups of similarly and dissimilarly prolific authors.  Dissimilarly prolific authors have markedly worse performance than similarly prolific authors for naive Bayes without Web1T in the Enron E-mail Corpus.
\begin{comment}
\paragraph*{} 
\begin{itemize}
\item Naive Bayes performance, with Web1T\% of 1 or greater, is consistent for similarly and dissimilarly prolific authors in the Enron E-mail Corpus.
\end{itemize}

\paragraph*{Curvature} For Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1} shows three closely grouped curves.  Just like in Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0}, the curvature of all three curves progresses from down and right to more up and left as group size increases.  
\paragraph*{Grouping}The grouping of the three curves becomes closer as group size increases with all three curves merging at a group size of 150. 
\paragraph*{Position} The left/right position for naive Bayes with Web1T\% of 1 is consistent through all group sizes. This shows that increasing group size has less effect on the top and bottom performing authors than on the average performing authors.
\paragraph*{Impact} Naive Bayes using Web1T as a vocabulary performs consistently across similarly and dissimilarly prolific authors with better performance than naive Bayes without Web1T in the Enron E-mail Corpus.
\end{comment}

	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-liblinear-twitter-GB3-ALL-0-crop}
		\caption{Graphs of the Cumulative Distribution of Authors Over F-Score for the NPS Twitter Short Message Corpus using SVM. Each panel in this figure shows SVM using GB3 for the Enron E-mail Corpus.  Each panel represents a different group size.  From top-left to bottom-right, those group sizes are 5, 10, 25, 50, 75, and 150.   The blank graph in the sixth panel represents a author-feature pairing that was too large for libLinear to execute as described in Section 3.2.2 and Section 4.1.  The curves in each graph are: Small-To-Large (STL), Small-And-Large (SAL), and Random (RAN).  STL represents groups of similarly prolific authors.  SAL represents groups of dissimilarly prolific authors.  RAN represents authors of random prolificity grouped together.  Curves with down and right curvature indicate better performance that curves with up and left curvature.  Curves positioned further to the right indicate better performance that curves positioned further to the left.  Curves with tighter grouping indicate more consistent performance than curves with looser grouping.}
		\label{fig:plot-tiled-cdf-summary-liblinear-twitter-GB3-ALL-0}
		\end{center}
	\end{figure}
\begin{itemize}
	\item Author detection in Twitter performs nearly identically for SVM and naive Bayes regardless of author prolificity groups.
\end{itemize} 

 Both Figures \ref{fig:plot-tiled-cdf-summary-liblinear-twitter-GB3-ALL-0} and \ref{fig:plot-tiled-cdf-summary-nb-twitter-GB3-ALL-0} show the cumulative distribution graphs for Twitter.  Figure \ref{fig:plot-tiled-cdf-summary-liblinear-twitter-GB3-ALL-0} shows SVM and Figure \ref{fig:plot-tiled-cdf-summary-nb-twitter-GB3-ALL-0} shows naive Bayes.  
 \paragraph*{Curvature} The curvature for both figures is nearly identical.  In both figures, the first and second panels show a "S" shape indicative of few authors with low f-scores and few authors with high f-scores.  Both figures show a steady progression from the first panel, group size 5, to the sixth panel, group size 150, of the "S" shape becoming more of an up and left curve, indicating increasing low f-scores for more authors.  This clearly demonstrates the worsening performance of both SVM and naive Bayes against the Twitter Short Message Corpus as group size increases.
 \paragraph*{Grouping} The grouping for both figures is nearly identical.  The grouping is close for all curves through all group sizes. This shows both SVM and naive Bayes are unaffected by author prolificity groups in Twitter.
 \paragraph*{Position} The position for both figures is nearly identical. The position does not change through larger group sizes.  When combined with the change in curvature as group size increases, the constant position indicates that the top and bottom performing authors have unchanged f-scores while more average performing authors have worsening f-scores.
 \paragraph*{Impact}  Figures \ref{fig:plot-tiled-cdf-summary-liblinear-twitter-GB3-ALL-0}, SVM for Twitter, and Figure \ref{fig:plot-tiled-cdf-summary-nb-twitter-GB3-ALL-0} naive Bayes for Twitter, demonstrate virtually no performance difference between SVM and naive Bayes.  Whether this lack of classifier performance difference is a phenomenon of the language used in Twitter or is simply a result of the small size of the Twitter corpus is left as a question for future work.
	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-nb-twitter-GB3-ALL-0-crop}
		\caption{Graphs of the Cumulative Distribution of Authors Over F-Score for the NPS Twitter Short Message Corpus using Naive Bayes. Each panel in this figure shows naive Bayes using GB3 for the Enron E-mail Corpus.  Each panel represents a different group size.  From top-left to bottom-right, those group sizes are 5, 10, 25, 50, 75, and 150. The curves in each graph are: Small-To-Large (STL), Small-And-Large (SAL), and Random (RAN).  STL represents groups of similarly prolific authors.  SAL represents groups of dissimilarly prolific authors.  RAN represents authors of random prolificity grouped together.  Curves with down and right curvature indicate better performance that curves with up and left curvature.  Curves positioned further to the right indicate better performance that curves positioned further to the left.  Curves with tighter grouping indicate more consistent performance than curves with looser grouping.}
		\label{fig:plot-tiled-cdf-summary-nb-twitter-GB3-ALL-0}
		\end{center}
	\end{figure}
	
		\paragraph*{} Twitter was a new service in 2006 when the Google Web1T snapshot was taken.  There was no significant Twitter corpus for Google to crawl.  Twitter language has evolved significantly since its inception and may differ appreciably from standard English or even standard web verbiage.  If a new Web1T built from a Google database that has crawled Twitter terms regularly was available, then an increase in accuracy and cumulative distribution for f-scores would indicate that the poor performance of Twitter was due to a lack of appropriate tokens in the 2006 Web1T Corpus.  If an e-mail corpus became available from 2010, then these same tests, using the 2006 Web1T Corpus, could be run against that newer e-mail corpus to see if accuracy worsened.  If accuracy and cumulative distribution worsened, then the age of the Web1T Corpus is impacting results by not evolving as language evolves.  To make a more rigorous comparison between e-mail and short message requires an e-mail corpus created at approximately the same time as the short message corpus with a vocabulary created from a database snapshot from approximately the same time.

\begin{singlespace}
\section{Storage Requirements for Combinations of Classification Methods, Feature Types, and Vocabulary}
\end{singlespace}
	\paragraph*{} While the effectiveness of the method-feature combinations are important, these tools are of no use on a mobile device unless the tool can actually fit on the disk and within the RAM on the mobile device.  An important fact about determining the size of classifier models is that the size of the model in RAM does not equal the size of the model when written to a file.  For instance, a Java long (primitive) of 1 uses 8 bytes of RAM, but is represented in a file using only 4 bytes.  Similarly, there is a disparity between the UTF-8 value's byte size on disk and the object representation in RAM for many Java objects.  Thus, heap size could not be used as an accurate measurement of model size.
	\paragraph*{}To determine if any of these method-feature combinations will fit on a mobile device, a few combinations had exhaustive outputs of their model sizes computed.  After determining that the standard deviation for models with a vocabulary size greater than a Web1T\% of 0 was trivial, only a small sample of the remaining method-feature combinations were computed.  Due to the large size of many models, only one model size was calculated for many method-feature combinations.  
	\paragraph*{} Actually writing out these models to disk would have been extremely time consuming and a load on the already taxed Hamming High Performance Cluster.  To conduct the size measurements, the SVM models were written to a Java ByteArrayOutputStream.  Once the write was complete, the size of the ByteArrayOutputStream buffer was measured.  The worked well for models smaller than 2GB.  Models larger than 2GB caused the ByteArrayOutputStream to be "full" since the index for an ByteArrayOutputStream is limited to $2^{31}$ elements and each element in that array is a byte.  For any model larger than 2GB, the size for that model was not recorded and thus has no size record in Appendix M through Appendix P nor a score in the scoring tables in Appendix I through Appendix L.
	\paragraph*{} What constitutes a storage requirement for the method-feature combinations in this thesis depends on the vocabulary size and method used.  A Web1T\% of 0 in SVM requires no keys.mph or signature file, but does require a sizable vocabulary map.  For naive Bayes, a Web1T\% of 0 does not require a keys.mph file, signature file, count file, nor logprobs file, however a sizable vocabulary map is needed.  The sizes for each combination's keys.mph, signature, counts, logprobs, and average author size are included with totals in Appendix M through Appendix P.  To provide an intuition on the magnitude of sizes involved, Table \ref{tab:sample_vocab_reference_sizes} shows sizes for keys.mph, signature, counts, logprobs, and vocabmap for a few method-feature combinations.  Table \ref{tab:sample_vocab_reference_sizes} shows only the vocabmap size for the Web1T\% of 0.  This is because Web1T\% of 0 does not use keys.mph, signature, counts, or logprobs references, but does create its own vocabulary map.  Complete size tables are provided in Appendix M through Appendix P.
	
	\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | r | r | }
			\hline
			 &  &  & \multicolumn{6}{|c|}{Size (MB)}\\ \cline{4-9}
			\begin{sideways}Method\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Web1T\%\end{sideways} & \begin{sideways}keys.mph\end{sideways} & \begin{sideways}signature\end{sideways} & \begin{sideways}counts\end{sideways} & \begin{sideways}logprobs\end{sideways} & \begin{sideways}vocabmap\end{sideways} & \begin{sideways}Total\end{sideways}\\ \hline 
			SVM & GB3 & 0 & 0.00 & 0.00 & 0.00 & 0.00 & 54.31 & 54.31\\ \hline 
			SVM & GB3 & 1 & 3.21 & 12.11 & 0.00 & 0.00 & 0.00 & 15.32\\ \hline 
			SVM & GB3 & 2 & 6.41 & 24.22 & 0.00 & 0.00 & 0.00 & 30.63\\ \hline 
			SVM & GB3 & 4 & 12.82 & 48.44 & 0.00 & 0.00 & 0.00 & 61.27\\ \hline 
			SVM & GB3 & 8 & 25.64 & 96.89 & 0.00 & 0.00 & 0.00 & 122.53\\ \hline 
			SVM & GB3 & 16 & 51.31 & 193.85 & 0.00 & 0.00 & 0.00 & 245.15\\ \hline 
			SVM & GM1 & 0 & 0.00 & 0.00 & 0.00 & 0.00 & 1.40 & 1.40\\ \hline 
			SVM & GM1 & 1 & 0.07 & 0.27 & 0.00 & 0.00 & 0.00 & 0.34\\ \hline 
			SVM & GM1 & 2 & 0.14 & 0.54 & 0.00 & 0.00 & 0.00 & 0.69\\ \hline 
			SVM & GM1 & 4 & 0.29 & 1.09 & 0.00 & 0.00 & 0.00 & 1.37\\ \hline 
			SVM & GM1 & 8 & 0.58 & 2.17 & 0.00 & 0.00 & 0.00 & 2.75\\ \hline 
			SVM & GM1 & 16 & 1.15 & 4.35 & 0.00 & 0.00 & 0.00 & 5.50\\ \hline 
			NB & GB3 & 0 & 0.00 & 0.00 & 0.00 & 0.00 & 54.31 & 54.31\\ \hline 
			NB & GB3 & 1 & 3.21 & 12.11 & 48.44 & 48.44 & 0.00 & 112.20\\ \hline 
			NB & GB3 & 2 & 6.41 & 24.22 & 96.88 & 96.88 & 0.00 & 224.39\\ \hline 
			NB & GB3 & 4 & 12.82 & 48.44 & 193.78 & 193.78 & 0.00 & 448.83\\ \hline 
			NB & GB3 & 8 & 25.64 & 96.89 & 387.55 & 387.55 & 0.00 & 897.64\\ \hline 
			NB & GB3 & 16 & 51.31 & 193.85 & 775.39 & 775.39 & 0.00 & 1795.94\\ \hline 
			NB & GM1 & 0 & 0.00 & 0.00 & 0.00 & 0.00 & 1.40 & 1.40\\ \hline 
			NB & GM1 & 1 & 0.07 & 0.27 & 1.09 & 1.09 & 0.00 & 2.52\\ \hline 
			NB & GM1 & 2 & 0.14 & 0.54 & 2.17 & 2.17 & 0.00 & 5.04\\ \hline 
			NB & GM1 & 4 & 0.29 & 1.09 & 4.35 & 4.35 & 0.00 & 10.07\\ \hline 
			NB & GM1 & 8 & 0.58 & 2.17 & 8.70 & 8.70 & 0.00 & 20.14\\ \hline 
			NB & GM1 & 16 & 1.15 & 4.35 & 17.40 & 17.40 & 0.00 & 40.29\\ \hline
		\end{tabular}
		\caption{Sample of Vocabulary Reference File Sizes}
		\label{tab:sample_vocab_reference_sizes}
		\end{center}
	\end{table}
	

	\paragraph*{} It is quickly apparent from Table \ref{tab:sample_vocab_reference_sizes} that few of these files could be loaded into the RAM of a 16MB Dalvik VM.  If these files were used, they would have to be read directly from the microSD card, which is an expensive operation compared to reading from RAM.  A more thorough discussion of method-feature combinations is discussed in the last section of this chapter.
	
	\paragraph*{} Apart from the vocabulary references needed for the method-feature combinations, each method-feature combination produces a different authors model size.  Unlike the vocabulary reference files, the authors model file sizes vary greatly.  The model constructed for SVM consists of an array populated with the support vector for each author.  The model for naive Bayes consists of a Java hashmap.  That hashmap has an Integer object for a key and a Double object for its value.  The Integer object is the mapped integer value for a given token.  The Double object is the probability for that token during the training process.
	
	\paragraph*{} The impact of authors model size for a mobile device is important. Even if the vocabulary reference files can be accommodated by a mobile device, a large author model can push the storage requirement beyond the 16MB Dalvik VMs capability or even the capacity of common microSD cards.  It is important to note here that size on a file only provides a relative indicator of size in RAM for a given method-feature combination.  Actually measuring the impact of Dalvik VM in terms of RAM used versus storage requirements is left to future work as this study involves how model referencing is handled and how values on the file are converted to objects in memory. Table \ref{tab:sample_authors_model_sizes} shows a sample of author sizes for both SVM and naive Bayes authors models.  A complete list of average authors model sizes is provided in Appendix M through Appendix P.
	
	\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | r | r | }
			\hline
			 &  &  &  &  & \multicolumn{4}{|c|}{Size (MB)}\\ \cline{6-9}
			\begin{sideways}Corpus\end{sideways} & \begin{sideways}Method\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Group Size\end{sideways} & \begin{sideways}Web1T\%\end{sideways} & \begin{sideways}AVG\end{sideways} & \begin{sideways}MIN\end{sideways} & \begin{sideways}MAX\end{sideways} & \begin{sideways}STDDEV\end{sideways}\\ \hline
		enron & SVM & OSB3 & 5 & 0 & 15.254 & 8.020 & 31.368 & 5.840\\ \hline 
		enron & SVM & OSB3 & 5 & 1 & 259.320 & 211.231 & 262.991 & 7.944\\ \hline 
		enron & SVM & OSB3 & 5 & 2 & 521.039 & 422.022 & 530.023 & 11.188\\ \hline 
		enron & SVM & OSB3 & 5 & 4 & 1031.477 & 844.102 & 1039.616 & 26.316\\ \hline 
		enron & NB & OSB3 & 5 & 0 & 5.328 & 0.068 & 34.479 & 7.090\\ \hline 
		enron & NB & OSB3 & 5 & 1 & 8.528 & 0.075 & 54.680 & 11.243\\ \hline 
		enron & NB & OSB3 & 5 & 2 & 8.544 & 0.075 & 54.939 & 11.286\\ \hline 
		enron & NB & OSB3 & 5 & 4 & 8.550 & 0.075 & 55.054 & 11.305\\ \hline 
		enron & NB & OSB3 & 5 & 8 & 8.553 & 0.075 & 55.100 & 11.314\\ \hline 
		enron & NB & OSB3 & 5 & 16 & 8.554 & 0.075 & 55.121 & 11.317\\ \hline 
		twitter & SVM & GM1 & 5 & 0 & 0.088 & 0.076 & 0.108 & 0.007\\ \hline 
		twitter & SVM & GM1 & 5 & 1 & 1.568 & 1.546 & 1.614 & 0.013\\ \hline 
		twitter & SVM & GM1 & 5 & 2 & 3.064 & 3.043 & 3.109 & 0.013\\ \hline 
		twitter & SVM & GM1 & 5 & 4 & 6.050 & 6.013 & 6.099 & 0.015\\ \hline 
		twitter & SVM & GM1 & 5 & 8 & 12.034 & 12.011 & 12.079 & 0.013\\ \hline 
		twitter & SVM & GM1 & 5 & 16 & 23.952 & 23.869 & 24.038 & 0.037\\ \hline 
		twitter & NB & GM1 & 5 & 0 & 0.024 & 0.016 & 0.045 & 0.005\\ \hline 
		twitter & NB & GM1 & 5 & 1 & 0.040 & 0.034 & 0.050 & 0.003\\ \hline 
		twitter & NB & GM1 & 5 & 2 & 0.040 & 0.035 & 0.051 & 0.003\\ \hline 
		twitter & NB & GM1 & 5 & 4 & 0.040 & 0.036 & 0.052 & 0.003\\ \hline 
		twitter & NB & GM1 & 5 & 8 & 0.040 & 0.034 & 0.053 & 0.003\\ \hline 
		twitter & NB & GM1 & 5 & 16 & 0.040 & 0.035 & 0.050 & 0.003\\ \hline 
		\end{tabular}
		\caption{Sample of Authors Model File Sizes}
		\label{tab:sample_authors_model_sizes}
		\end{center}
	\end{table}

\section{Classification Effectiveness Versus Storage Requirements}
\paragraph*{} With the resource constraints of mobile devices and the author detection requirements of this thesis, some method must be used to evaluate the tradeoff between accuracy and size.  For this thesis, we devise a united metric of efficacy, $score=\frac{accuracy}{size}$.  The storage requirements will be computed as the sum of keys.mph, signature, counts, logprobs, vocabmap, and average authors model size for each method-feature combination.  The complete set of scores are included in Appendix I through Appendix L.  

\paragraph*{}It is important to note that there are no scores for any authors model size over 2GB.  This is due to the limitations of measuring on-disk size for authors models with a ByteArrayOutputStream, but this limitation will not adversely affect the conclusions of this thesis.  Any authors model larger than 2GB is impractical for current mobile devices.  Also, a 2GB divisor for the score computation would put that method-feature combination out of contention for a top performer in this thesis.

\paragraph*{}  The top performing method-feature combination for the Enron E-mail Corpus was naive Bayes using GM1 for group size 5 with a score of 0.4495.  Table \ref{tab:top_enron_by_score} shows the top 20 scores along with accuracy and size information for the Enron E-mail Corpus.  All of these top performers use the GM1 feature type. The accuracy of these combinations is in the same range as the most accurate method-feature combinations. However, these accuracies are mostly for group sizes of 5, 10, and 25, which limits the applicability of the tools in this thesis.  There is only one combination for group size 50 and only one combination of group size 75.  All of these top 20 scores have storage requirements under 16MB.

\paragraph*{}Based on Table \ref{tab:sample_authors_model_sizes}, it appears there are no method-feature combinations for group sizes of 50 and larger that will meet the 16MB limit set for storage requirements.  Analysis of Appendix I through Appendix L reveals a small number of method-feature combinations for groups sizes larger than 50 as shown in Table \ref{tab:method_feature_combos_over_gs_50_under_16MB}

	\begin{table}[!htbp]
	\begin{center}
		\begin{tabular}{|r|r|r|r|r|}
		\hline
		\begin{sideways}Corpus\end{sideways} & \begin{sideways}Method\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Group Size\end{sideways} & \begin{sideways}Web1T\%\end{sideways}\\ \hline
		enron	& SVM	& GM1	& 50	& 0		\\ \hline
		twitter	& SVM	& GM1	& 50	& 0		\\ \hline
		twitter	& SVM	& GM1	& 75	& 0		\\ \hline
		twitter	& SVM	& GM1	& 150	& 0		\\ \hline
		twitter	& SVM	& GM2	& 50	& 0		\\ \hline
		enron	& NB	& GM1	& 50	& 0,1,2,4	\\ \hline
		enron	& NB	& GM1	& 75	& 0,1,2,4	\\ \hline
		enron	& NB	& GM1	& 150	& 0,1,2		\\ \hline
		twitter	& NB	& GM1	& 50	& 0,1,2,4	\\ \hline
		twitter	& NB	& GM1	& 75	& 0,1,2,3	\\ \hline
		twitter	& NB	& GM1	& 150	& 0,1,2		\\ \hline
		twitter	& NB	& GM2	& 50	& 0		\\ \hline
		twitter	& NB	& GM2	& 75	& 0		\\ \hline
		twitter	& NB	& GM2	& 150	& 0		\\ \hline
		twitter	& NB	& GM5	& 50	& 0		\\ \hline
		twitter	& NB	& GM5	& 75	& 0		\\ \hline
		twitter	& NB	& GM5	& 150	& 0		\\ \hline
		twitter	& NB	& GB3	& 50	& 0		\\ \hline
		twitter	& NB	& GB3	& 75	& 0		\\ \hline
		twitter	& NB	& GB3	& 150	& 0		\\ \hline
		twitter	& NB	& OSB3	& 50	& 0		\\ \hline
		twitter	& NB	& OSB3	& 75	& 0		\\ \hline
		twitter	& NB	& OSB3	& 150	& 0		\\ \hline
		\end{tabular}
		\caption{Method-Feature Combinations for Groups Sizes Less Than 50 With A Storage Requirement Less Than 16MB}
		\label{tab:method_feature_combos_over_gs_50_under_16MB}
	\end{center}
	\end{table}

\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | r | }
			\hline
			\begin{sideways}Method\end{sideways} & \begin{sideways}Corpus\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Group Size\end{sideways} & \begin{sideways}Web1T\end{sideways} \% & \begin{sideways}Score\end{sideways} & \begin{sideways}Accuracy\end{sideways} & \begin{sideways}Size(MB)\end{sideways}\\ \hline 
			
			NB & enron & GM1 & 5 & 0 & 0.4495 & 0.7215 & 1.60\\ \hline 
			SVM & enron & GM1 & 5 & 0 & 0.4374 & 0.8269 & 1.89\\ \hline 
			SVM & enron & GM1 & 5 & 1 & 0.3685 & 0.8233 & 2.23\\ \hline 
			NB & enron & GM1 & 10 & 0 & 0.3186 & 0.5768 & 1.81\\ \hline 
			SVM & enron & GM1 & 10 & 0 & 0.2789 & 0.7611 & 2.73\\ \hline 
			NB & enron & GM1 & 5 & 1 & 0.2262 & 0.6441 & 2.85\\ \hline 
			SVM & enron & GM1 & 5 & 2 & 0.2017 & 0.8216 & 4.07\\ \hline 
			SVM & enron & GM1 & 10 & 1 & 0.1800 & 0.7610 & 4.23\\ \hline 
			NB & enron & GM1 & 25 & 0 & 0.1683 & 0.4083 & 2.43\\ \hline 
			NB & enron & GM1 & 10 & 1 & 0.1634 & 0.5189 & 3.18\\ \hline 
			NB & enron & GM1 & 5 & 2 & 0.1212 & 0.6505 & 5.37\\ \hline 
			SVM & enron & GM1 & 25 & 0 & 0.1124 & 0.6845 & 6.09\\ \hline 
			SVM & enron & GM1 & 5 & 4 & 0.1071 & 0.8298 & 7.75\\ \hline 
			SVM & enron & GM1 & 10 & 2 & 0.1024 & 0.7594 & 7.42\\ \hline 
			NB & enron & GM1 & 25 & 1 & 0.0950 & 0.3956 & 4.16\\ \hline 
			NB & enron & GM1 & 10 & 2 & 0.0915 & 0.5215 & 5.70\\ \hline 
			NB & enron & GM1 & 50 & 0 & 0.0903 & 0.3126 & 3.46\\ \hline 
			SVM & enron & GM1 & 25 & 1 & 0.0648 & 0.6847 & 10.56\\ \hline 
			NB & enron & GM1 & 75 & 0 & 0.0648 & 0.2912 & 4.50\\ \hline 
			NB & enron & GM1 & 5 & 4 & 0.0635 & 0.6610 & 10.40\\ \hline 

		\end{tabular}
		\caption{Highest Scoring Method-Feature Combinations for the Enron E-mail Corpus}
		\label{tab:top_enron_by_score}
	\end{center}
\end{table}

\paragraph*{}  The top performing method-feature combination for the Twitter Short Message Corpus was naive Bayes using feature type GM1 for a group size of 5.  Table \ref{tab:top_twitter_by_score} shows the top 20 scores along with accuracy and size information for the Twitter Short Message Corpus.  The accuracy of these combinations is in the same range as the most accurate method-feature combinations. The range of groups sizes that made the top 20 scores is much larger than for the Enron E-mail Corpus because authors in the Enron E-mail Corpus are much more prolific.  There are three combinations for group size 50, two combinations of group size 75, and two combinations of group size 150. All of the top 20 performing score combinations have a storage requirement of less than 16MB.

\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | r | }
			\hline
			\begin{sideways}Method\end{sideways} & \begin{sideways}Corpus\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Group Size\end{sideways} & \begin{sideways}Web1T\end{sideways} \% & \begin{sideways}Score\end{sideways} & \begin{sideways}Accuracy\end{sideways} & \begin{sideways}Size(MB)\end{sideways}\\ \hline 
			
			NB	& twitter	& GM1	& 5	& 0	& 2.8233	& 0.6264	& 0.2219\\ \hline 
			SVM	& twitter	& GM1	& 5	& 0	& 2.1731	& 0.6212	& 0.2859\\ \hline 
			NB	& twitter	& GM1	& 10	& 0	& 1.9815	& 0.4869	& 0.2457\\ \hline 
			SVM	& twitter	& GM1	& 10	& 0	& 1.0850	& 0.4762	& 0.4389\\ \hline 
			NB	& twitter	& GM1	& 25	& 0	& 1.0593	& 0.3357	& 0.3169\\ \hline 
			NB	& twitter	& GM1	& 50	& 0	& 0.5347	& 0.2326	& 0.4350\\ \hline 
			NB	& twitter	& GM2	& 5	& 0	& 0.4866	& 0.5711	& 1.1738\\ \hline 
			NB	& twitter	& GM2	& 10	& 0	& 0.3644	& 0.4439	& 1.2181\\ \hline 
			SVM	& twitter	& GM2	& 5	& 0	& 0.3503	& 0.4844	& 1.3830\\ \hline 
			SVM	& twitter	& GM1	& 25	& 0	& 0.3301	& 0.3461	& 1.0483\\ \hline 
			NB	& twitter	& GM1	& 75	& 0	& 0.3291	& 0.1820	& 0.5530\\ \hline 
			SVM	& twitter	& GM1	& 5	& 1	& 0.3257	& 0.6228	& 1.9123\\ \hline 
			NB	& twitter	& GM2	& 25	& 0	& 0.2380	& 0.3215	& 1.3508\\ \hline 
			NB	& twitter	& GM1	& 5	& 1	& 0.2210	& 0.5652	& 2.5578\\ \hline 
			SVM	& twitter	& GM2	& 10	& 0	& 0.1911	& 0.3700	& 1.9363\\ \hline 
			NB	& twitter	& GB3	& 5	& 0	& 0.1868	& 0.6179	& 3.3084\\ \hline 
			SVM	& twitter	& GM1	& 5	& 2	& 0.1639	& 0.6147	& 3.7511\\ \hline 
			NB	& twitter	& GM1	& 10	& 1	& 0.1625	& 0.4221	& 2.5972\\ \hline 
			NB	& twitter	& GM2	& 50	& 0	& 0.1598	& 0.2509	& 1.5700\\ \hline 
			NB	& twitter	& GB3	& 10	& 0	& 0.1440	& 0.4948	& 3.4368\\ \hline  

		\end{tabular}
		\caption{Highest Scoring Method-Feature Combinations for the Twitter Short Message Corpus}
		\label{tab:top_twitter_by_score}
	\end{center}
\end{table}

\paragraph{} With the scores measure for each method-feature combination in hand, the shortcoming of using $score = \frac{accuracy}{size}$ become apparent.  Table \ref{tab:top_enron_by_score} indicates that naive Bayes using GM1 for group size 5 is the best feature-combination to choose for a mobile device.  However, the second highest score, SVM using GM1 for group size 5 has an accuracy of 0.6212 where the top scoring combination has an accuracy of 0.6264, a full 0.05 better than the second top scorer.  An even more important limitation to this approach is the heavy bias of group size on the scoring process.  To address this, Table \ref{tab:top_enron_by_score_all_groups} for the Enron E-mail Corpus, and Table \ref{tab:top_twitter_by_score_all_groups} for the Twitter Short Message Corpus, were constructed to show the score for each feature-method-percentage combination that could cover all group sizes with score averaged over all group sizes.

\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | }
			\hline
			\begin{sideways}Method\end{sideways} & \begin{sideways}Corpus\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Web1T\end{sideways} \% & \begin{sideways}Score\end{sideways} & \begin{sideways}Accuracy\end{sideways} & \begin{sideways}Size(MB)\end{sideways}\\ \hline 

			NB	& enron	& GM1	& 0	& 0.1195	& 0.4259	& 3.5637\\ \hline 
			NB	& enron	& GM1	& 1	& 0.0648	& 0.3868	& 5.9718\\ \hline 
			NB	& enron	& GM1	& 2	& 0.0464	& 0.3941	& 8.5024\\ \hline 
			SVM	& enron	& GM1	& 0	& 0.0402	& 0.6890	& 17.1428\\ \hline 
			NB	& enron	& GM1	& 4	& 0.0297	& 0.4027	& 13.5433\\ \hline 
			SVM	& enron	& GM1	& 1	& 0.0291	& 0.6851	& 23.5517\\ \hline 
			NB	& enron	& GM2	& 0	& 0.0235	& 0.6060	& 25.7537\\ \hline 
			SVM	& enron	& GM1	& 2	& 0.0179	& 0.6869	& 38.3513\\ \hline 
			NB	& enron	& GM1	& 8	& 0.0170	& 0.4022	& 23.6185\\ \hline 
			SVM	& enron	& GM1	& 4	& 0.0118	& 0.6955	& 58.8048\\ \hline 
			NB	& enron	& GM1	& 16	& 0.0093	& 0.4084	& 43.7648\\ \hline 
			NB	& enron	& GB3	& 0	& 0.0071	& 0.5833	& 82.2663\\ \hline 
			NB	& enron	& GM2	& 1	& 0.0066	& 0.4101	& 61.7548\\ \hline 
			SVM	& enron	& GM2	& 0	& 0.0062	& 0.7772	& 124.3990\\ \hline 
			SVM	& enron	& GM1	& 8	& 0.0054	& 0.6872	& 126.8721\\ \hline 
			NB	& enron	& GM5	& 0	& 0.0048	& 0.6218	& 128.3638\\ \hline 
			NB	& enron	& GB3	& 1	& 0.0044	& 0.6866	& 156.4631\\ \hline 
			NB	& enron	& OSB3	& 0	& 0.0042	& 0.7310	& 173.9431\\ \hline 
			NB	& enron	& GM2	& 2	& 0.0038	& 0.4546	& 118.2138\\ \hline 
			SVM	& enron	& GB3	& 0	& 0.0036	& 0.7809	& 218.5693\\ \hline 
			SVM	& enron	& GM1	& 16	& 0.0034	& 0.6962	& 204.5598\\ \hline

		\end{tabular}
		\caption{Highest Scoring Method-Feature Combinations Over All Groups for the Enron E-mail Corpus}
		\label{tab:top_enron_by_score_all_groups}
	\end{center}
\end{table}

\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | }
			\hline
			\begin{sideways}Method\end{sideways} & \begin{sideways}Corpus\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Web1T\end{sideways} \% & \begin{sideways}Score\end{sideways} & \begin{sideways}Accuracy\end{sideways} & \begin{sideways}Size(MB)\end{sideways}\\ \hline 
			
		NB	& twitter	& GM1	& 0	& 0.7413	& 0.3315	& 0.4471\\ \hline 
		NB	& twitter	& GM2	& 0	& 0.2065	& 0.3291	& 1.5934\\ \hline 
		SVM	& twitter	& GM1	& 0	& 0.1212	& 0.3542	& 2.9234\\ \hline 
		NB	& twitter	& GM1	& 1	& 0.1028	& 0.3015	& 2.9332\\ \hline 
		NB	& twitter	& GB3	& 0	& 0.0811	& 0.3670	& 4.5253\\ \hline 
		NB	& twitter	& GM1	& 2	& 0.0562	& 0.3062	& 5.4527\\ \hline 
		NB	& twitter	& GM5	& 0	& 0.0488	& 0.1732	& 3.5527\\ \hline 
		NB	& twitter	& OSB3	& 0	& 0.0401	& 0.4025	& 10.0340\\ \hline 
		NB	& twitter	& GM1	& 4	& 0.0290	& 0.3044	& 10.4871\\ \hline 
		SVM	& twitter	& GM1	& 1	& 0.0215	& 0.3556	& 16.5257\\ \hline 
		SVM	& twitter	& GM2	& 0	& 0.0214	& 0.2768	& 12.9316\\ \hline 
		NB	& twitter	& GM1	& 8	& 0.0149	& 0.3057	& 20.5600\\ \hline 
		SVM	& twitter	& GM1	& 2	& 0.0114	& 0.3551	& 31.2754\\ \hline 
		SVM	& twitter	& GB3	& 0	& 0.0078	& 0.3183	& 40.9074\\ \hline 
		NB	& twitter	& GM1	& 16	& 0.0075	& 0.3057	& 40.7048\\ \hline 
		SVM	& twitter	& GM1	& 4	& 0.0059	& 0.3577	& 60.7786\\ \hline 
		NB	& twitter	& GM2	& 1	& 0.0056	& 0.3280	& 58.7434\\ \hline 
		SVM	& twitter	& GM5	& 0	& 0.0038	& 0.1271	& 33.0844\\ \hline 
		SVM	& twitter	& OSB3	& 0	& 0.0036	& 0.3211	& 88.9854\\ \hline 
		\end{tabular}
		\caption{Highest Scoring Method-Feature Combinations Over All Groups for the Twitter Short Message Corpus}
		\label{tab:top_twitter_by_score_all_groups}
	\end{center}
\end{table}

\paragraph*{} The top method-feature combinations in Table \ref{tab:top_enron_by_score_all_groups} are still dominated by GM1 as a feature type.  Naive Bayes using GM1 and a Web1T\%=0 had a higher score than SVM using GM1 and a Web1T\%=0, but the SVM accuracy is 0.1284 higher than the naive Bayes accuracy.  This shows again that this scoring method by itself does not produce an optimal feature-method combination on its own.

\paragraph*{} Similarly, the top method-feature combinations for the Twitter Short Message Corpus in Table \ref{tab:top_twitter_by_score_all_groups} are GM1.  However, there is a much wider mix of feature types in the Twitter Corpus than was seen in the Enron Corpus.  Also, naive Bayes outperforms its SVM counterparts in some situations.  Just like with Enron, the highest scoring method-feature combination is not necessarily the most appropriate combination for deployment on a mobile phone.  For the Twitter Corpus, naive Bayes using OSB3 and a Web1T\%=0 has a 40.25\% accuracy with a size of 10.0340MB.  This is the highest accuracy on the top 20 list that is still below 16MB.  \begin{comment}There are several accuracies above 0.5 that have significantly smaller storage requirements.\end{comment}

\paragraph*{} To more clearly illustrate the results of accuracy and storage size on the Enron E-mail Corpus and the Twitter Short Message Corpus, Figures \ref{fig:plot-scatter-enron} and \ref{fig:plot-scatter-twitter} were generated.  In these figures:
	\begin{itemize}
		\item Circles are tests using SVM
		\item Triangles are tests using naive Bayes
		\item Red symbols are tests using GM1
		\item Cyan symbols are tests using GM2
		\item Yellow symbols are tests using GM5
		\item Green symbols are tests using GB3
		\item Blue symbols are tests using OSB3
		\item The smallest symbols are for a group size of 5
		\item The largest symbols are for a group size of 150
		\item The x-axis, Storage Size (MB), is a logarithmic-2 scale to better distinguish items on the left of the graph
		\item The y-axis is accuracy. The more accurate method-feature combinations are higher in the graph
		\item The method-feature combinations with a smaller storage requirement are further left on the graph
	\end{itemize}
		
\definecolor{MyDarkYellow}{rgb}{0.75,0.65,0.0}	
\definecolor{MyOliveGreen}{rgb}{0,0.4,0}
		
\paragraph*{}
	\begin{sidewaysfigure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[scale=1.1]{plot-scatter-size-accuracy-enron-crop}
			
		\begin{tabular}{cccccc}
			
			  	& GM1	& GM2	& GM5	& GB3	& OSB3	\\
			NB	& $ \color{red} \blacktriangle$ & $\color{cyan} \blacktriangle$ & $\color{MyDarkYellow} \blacktriangle$ & $\color{MyOliveGreen} \blacktriangle$ & $\color{blue} \blacktriangle$ \\ 					
			SVM	& $ \color{red} \CIRCLE$ & $\color{cyan} \CIRCLE$ & $\color{MyDarkYellow} \CIRCLE$ & $\color{MyOliveGreen} \CIRCLE$ & $\color{blue} \CIRCLE$ \\
		\end{tabular}
		\begin{singlespace}
		Symbol size represents group size.  Smallest = group size 5.  Largest = group size 150.  
		\end{singlespace}
		\caption{Scatter-Plot of Enron E-mail Corpus Tests}
		\label{fig:plot-scatter-enron}
		\end{center}
	\end{sidewaysfigure}
	
\paragraph*{} Figure \ref{fig:plot-scatter-enron} shows several notable trends for accuracy in the Enron E-Mail Corpus.  These are:
	\begin{itemize}
		\item Both naive Bayes and SVM performed well against the Enron E-Mail Corpus: There is little white space at the top of the graph.  While the graph tops out at 90\% accuracy, the bulk of symbols in the graph are toward the top of the graph.  
		\item Increasing Web1T\% use gives no greater accuracy.  The upper leftmost point represent SVM using GM1 with Web1T\% of 0.  The trail of red circles to the right of this point represent SVM using GM1 with Web1T\% values of 1,2,4,8, and 16.  The points provide roughly the same accuracy at an increasing cost of storage.  This could be represented as a horizontal line through the Web1T\% values for SVM for GM1.  This pattern repeats itself for most symbols to the left of $2^6$MB.
		\item More complex feature types like GB3 and OSB3 incur greater storage requirements with very slight increases in accuracy. The upper leftmost point is not the highest accuracy point on the graph.  There are numerous light blue (GM2), dark blue (OSB3), and green (GB3) circles with higher accuracies.  Also there are some dark blue (OSB3) and green (GB3) triangles with higher accuracies.  However, the storage requirement for the first point encountered with a higher accuracy than the upper leftmost point is 16 times large than the upper leftmost red circle.  This is a significant storage cost compared to the increase in accuracy.  The size penalty versus improved accuracy only gets worse as this line of maximum values moves right.
		\item More complex feature types like GB3 and OSB3 have great potential for author detection when storage requirements are not an issue. All of the highest accuracy points are dark blue (OSB3) and green (GB3) symbols.  Both triangles (naive Bayes) and circles (SVM) are represented.  This shows that OSB3 and GB3 give high accuracies using both SVM and naive Bayes.  
		\item There are method-feature combinations that can fit within the storage requirement of 16MB or less. There are numerous symbols to the left of $2^4$MB.  $2^4$MB is an important line because the default heap size limit for a Dalvik VM is 16MB.  While it is true that a storage size of 16MB does not necessarily equate to 16MB of heap, 16MB is still a good relative indicator of how well a model could fit into a Dalvik VM.
		\item SVM generally outperforms naive Bayes for the Enron E-mail corpus. The circles (SVM) generally hold higher positions in the plot while triangles (naive Bayes) generally hold lower positions in the graph. 
		\item Increasing group size has an adverse effect on accuracy. There are diagonal lines, from upper left to lower right, of same shape, same color, different size symbols representing the fall in accuracy and increase in size for a method-feature combination as the group size increases from 5 to 150.  For example, there is a clear line of increasingly large, red circles from the uppermost red circle at (accuracy=0.82, size=$2^0$MB) fall successively to the large red circle at (accuracy=0.61, size=$2^4$MB).  This pattern is repeated through the graph with the slope becoming steeper as the graph progresses to the right.  As an example of a steep slope for this line, take the small light blue triangle at (accuracy=0.6, size=$2^4$MB).  There is a steep line of increasingly large, light blue triangles down to (accuracy=0.45, size=$2^5$MB).  The increasing slope is due to the logarithmic scale of the graph, but shows that increasing group size has an adverse effect on accuracy.
		\item Naive Bayes performs better for GB3 and OSB3 feature types with a Web1T\% of 1 or larger. The triangles (naive Bayes), do not appear in the upper part of the graph until after $2^7$MB.  Also, these more accurate naive Bayes points are competing well with their SVM counterparts for accuracy, but carry more size as there are no circles past $2^{11}$MB. There are triangles all the way out to $2^{13}$.  This is an artifact of naive Bayes for Web1T\% $\ge$ 1 having to carry a large keys.mph file, large signature file, as well as large counts and logprob files. It is important to remember that any storage model with an authors model size of $\ge$ 2GB is not plotted, which explains the lack of large blue triangle continuing down the $2^{13}$MB line.
		\item One method-feature combination, SVM using GM2, performs better for a group size of 150 authors than other method-feature combinations when storage requirement is taken into consideration.  One symbol stands out on the graph, the light blue, large circle at (accuracy=0.74, size=$2^9$ MB).  This is circle represents a group size of 150 with a very high accuracy compared to other circles representing a group size of 150.  At $2^9$ MB, this method-feature combination is by no means light on storage, but produces an accuracy of over 0.70 for a group size of 150 authors.  That is a standout achievement compared to the other symbols with a group size of 150.
		\item SVM cannot handle all cases of author group sizes combined with all feature types.  There are fewer circles than triangles on the graph.  This is due to the internal model limitations of libLinear.  Naive Bayes is able to handle all sizes of authors and models where the libLinear limit of author-feature pairs is $2^{31}$ pairs.
		\item All method-feature combinations perform above an accuracy of 10\%. No symbols, circle or triangle, sit on the bottom line of the graph.  The worst accuracy shown is just below 0.2. No symbol made it to the top of the graph meaning no accuracy equaled 1.0.
	\end{itemize}
		
	
\definecolor{MyDarkYellow}{rgb}{0.75,0.65,0.0}	
\definecolor{MyOliveGreen}{rgb}{0,0.4,0}
				
\paragraph*{}
	\begin{sidewaysfigure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[scale=1.1]{plot-scatter-size-accuracy-twitter-crop}

		\begin{tabular}{cccccc}
			
			  	& GM1	& GM2	& GM5	& GB3	& OSB3	\\
			NB	& $ \color{red} \blacktriangle$ & $\color{cyan} \blacktriangle$ & $\color{MyDarkYellow} \blacktriangle$ & $\color{MyOliveGreen} \blacktriangle$ & $\color{blue} \blacktriangle$ \\ 					
			SVM	& $ \color{red} \CIRCLE$ & $\color{cyan} \CIRCLE$ & $\color{MyDarkYellow} \CIRCLE$ & $\color{MyOliveGreen} \CIRCLE$ & $\color{blue} \CIRCLE$ \\	
			
		\end{tabular}
		\begin{comment}	
		\begin{tabular}{ccc}
			& NB 					& SVM 					\\
		GM1 	& $\color{red} \blacktriangle$		& $\color{red} \CIRCLE$			\\
		GM2 	& $\color{cyan} \blacktriangle$		& $\color{cyan} \CIRCLE$		\\
		GM5 	& $\color{MyDarkYellow} \blacktriangle$	& $\color{MyDarkYellow} \CIRCLE$	\\
		GB3 	& $\color{MyOliveGreen} \blacktriangle$	& $\color{MyOliveGreen} \CIRCLE$	\\
		OSB3 	& $\color{red} \blacktriangle$		& $\color{red} \CIRCLE$			\\
		\end{tabular}
		
		\end{comment}
		\begin{singlespace}
		Symbol size represents group size.  Smallest = group size 5.  Largest = group size 150.  
		\end{singlespace}
		
		\caption{Scatter-Plot of Twitter Short Message Corpus Tests}
		\label{fig:plot-scatter-twitter}
		\end{center}
	\end{sidewaysfigure}

\paragraph*{} Figure \ref{fig:plot-scatter-twitter} shows several notable trends for accuracy in the Twitter Short Message Corpus.  These are:
	\begin{itemize}
		\item There is significant whitespace at the top of the graph.  This shows that both naive Bayes and SVM produced lower accuracies against the Twitter Short Message Corpus than against the Enron E-mail Corpus.
		\item The upper leftmost point is SVM for GM1 using Web1T\% of 0.  This leftmost point is not the highest accuracy on the graph.  The highest accuracy belongs to the dark blue triangle, representing naive Bayes for OSB3.  While there is still a line of red circles extending right from the left most red circle, there is also a line of dark blue and green triangles as well light blue circles extending to the right.  This indicates that multiple feature types, GM1, GM2, OSB3, and GB3 all performed similarly for group sizes of 5.
		\item There are many symbols to the left of $2^4$MB. $2^4$MB is an important line because the default heap size limit for a Dalvik VM is 16MB.  While it is true that a storage size of 16MB does not necessarily equate to 16MB of heap, 16MB is still a good relative indicator of how well a model could fit into a Dalvik VM.
		\item No symbols on the Twitter graph stand out as unusual or unexpected.  The entire graph progresses downward by group size.
		\item There is no clear grouping of triangle and circles in any portion of the Twitter graph. This indicates that neither SVM nor naive Bayes held a clear accuracy advantage at any part of the graph.
		
	\end{itemize}

\paragraph*{} Comparing the performance of the method-feature combinations in this thesis against the Enron E-Mail Corpus and the Twitter Short Message Corpus yields some significant differences:
	\begin{itemize}
		\item The symbols in the Enron graph tend higher in accuracy than the symbols in the Twitter graph.  This shows that the method-feature combinations in this thesis produced higher accuracies for an e-mail corpus than against a short message corpus.
		\item There is significant mixture of colors of different shapes and sizes at the top of the right side of the Enron graph.  The large, light blue circle  at (accuracy=0.74, size=$2^9$MB) is a notable data point showing high accuracy for a group size of 150.  The Twitter graph has no such exceptional data points.  The data in the Twitter graph is very regular.  Accuracies fall as group sizes fall nearly identically across all method-feature combinations.  This result means that the test either had too little Twitter text to train on, the wrong types of feature types to use against the 140 character limited structure of short messages, or the compact language of Twitter was not well represented by Web1T or sampled well by the bootstrapping (Web1T\% of 0) method.
		\item There is no clear grouping of triangle and circles in the Twitter graph.  On the left side of the Enron graph, there was a clear delineation between circles at the top of the graph and triangles at the bottom of the graph.  This shows that neither SVM nor naive Bayes held a clear accuracy advantage at any part of the graph.  The top performing method-feature combinations all fell in a nearly straight line across the 62\% accuracy line for Twitter.  This is noticeably different than the top performance line for Enron of 85\%.


		\item There are fewer circles than triangles on the graph.  This is due to the internal model limitations of libLinear.  Naive Bayes is able to handle all sizes of authors and models where the libLinear limit of author-feature pairs is $2^{31}$ pairs.
		\item There are symbols, circles and triangles, sitting on the bottom line of the graph.  The worst accuracies shown are on the 0.1 line. 
	\end{itemize}

\section{Ability to Execute on an Android Mobile Phone}
\paragraph*{} With scores calculated alongside accuracy and storage requirements, we can determine feasibility on a mobile device.  The previous section clearly showed that $score = \frac{accuracy}{size}$ by itself does not provide an optimal solution for choosing an author detection method-feature combination on a mobile device. Tables \ref{tab:top_enron_by_score_all_groups_under_16mb} and \ref{tab:top_twitter_by_score_all_groups_under_16mb} show the highest scoring method-feature combinations that have storage requirements less than 16MB, ordered by accuracy.  For the Enron Corpus, Table \ref{tab:top_twitter_by_score_all_groups_under_16mb} shows that the best accuracy achievable using the tools of this thesis is 77.35\%.  For the Twitter Corpus, Table \ref{tab:top_twitter_by_score_all_groups_under_16mb} shows that the best accuracy achievable using the tools of this thesis is 55.25\%. 

\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | r | r |}
			\hline
			\begin{sideways}Method\end{sideways} & \begin{sideways}Corpus\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Web1T\end{sideways} \% & \begin{sideways}Score\end{sideways} & \begin{sideways}Accuracy\end{sideways} & \begin{sideways}Size(MB)\end{sideways} &\begin{sideways}MLE\end{sideways} & \begin{sideways}F-Score\end{sideways}\\ \hline

NB	& enron	& GM1	& 0	& 0.1195	& 0.4259	& 3.5637	& 0.2218	& 0.1949\\ \hline 
NB	& enron	& GM1	& 1	& 0.0648	& 0.3868	& 5.9718	& 0.2230	& 0.3451\\ \hline 
NB	& enron	& GM1	& 2	& 0.0464	& 0.3941	& 8.5024	& 0.2254	& 0.3498\\ \hline 
NB	& enron	& GM1	& 4	& 0.0297	& 0.4027	& 13.5433	& 0.2209	& 0.3555\\ \hline

\end{tabular}
		\caption{Highest Scoring Method-Feature Combinations Over All Groups for the Enron E-mail Corpus With A Storage Requirement Less Than 16MB}
		\label{tab:top_enron_by_score_all_groups_under_16mb}
	\end{center}
\end{table}

\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | r| r | }
			\hline
			\begin{sideways}Method\end{sideways} & \begin{sideways}Corpus\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Web1T\end{sideways} \% & \begin{sideways}Score\end{sideways} & \begin{sideways}Accuracy\end{sideways} & \begin{sideways}Size(MB)\end{sideways} &\begin{sideways}MLE\end{sideways} & \begin{sideways}F-Score\end{sideways}\\ \hline

			NB	& twitter	& GM1	& 0	& 0.7413	& 0.3315	& 0.4471	& 0.1023	& 0.2882\\ \hline 
			NB	& twitter	& GM2	& 0	& 0.2065	& 0.3291	& 1.5934	& 0.1023	& 0.2925\\ \hline 
			SVM	& twitter	& GM1	& 0	& 0.1212	& 0.3542	& 2.9234	& 0.1023	& 0.3331\\ \hline 
			NB	& twitter	& GM1	& 1	& 0.1028	& 0.3015	& 2.9332	& 0.1015	& 0.2689\\ \hline 
			NB	& twitter	& GM5	& 0	& 0.0488	& 0.1732	& 3.5527	& 0.1033	& 0.1341\\ \hline 
			NB	& twitter	& GB3	& 0	& 0.0811	& 0.3670	& 4.5253	& 0.1034	& 0.3285\\ \hline 
			NB	& twitter	& GM1	& 2	& 0.0562	& 0.3062	& 5.4527	& 0.1017	& 0.2734\\ \hline 
			NB	& twitter	& OSB3	& 0	& 0.0401	& 0.4025	& 10.0340	& 0.1029	& 0.3813\\ \hline 
			NB	& twitter	& GM1	& 4	& 0.0290	& 0.3044	& 10.4871	& 0.1017	& 0.2715\\ \hline 
			SVM	& twitter	& GM2	& 0	& 0.0214	& 0.2768	& 12.9316	& 0.1023	& 0.2594\\ \hline 

\end{tabular}
		\caption{Highest Scoring Method-Feature Combinations Over All Groups for the Twitter Short Message Corpus With A Storage Requirement Less Than 16MB}
		\label{tab:top_twitter_by_score_all_groups_under_16mb}
	\end{center}
\end{table}

\paragraph*{} The Enron E-mail Corpus has 7 method-feature combinations with a storage requirement of less than 16MB. The Twitter Short Message Corpus has 14 method-feature combinations across all group sizes with a storage requirement under 16MB.  Looking closely at the values of size and accuracy, there is little difference between the three highest accuracies in Table \ref{tab:top_enron_by_score_all_groups_under_16mb} but the third highest accuracy is more than double the size of the highest accuracy.  That makes the choice of SVM GM1 0 clearly the most appropriate choice for a mobile device. For the Twitter corpus, the top accuracy of 55.25\% for naive Bayes using OSB3 is only slightly higher than 52.03\% for naive Bayes using GB3 with a size that is which is less than half of OSB3.  Naive Bayes using GB3 would be more appropriate for a mobile device.

