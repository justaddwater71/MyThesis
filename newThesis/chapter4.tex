\chapter{Results and Analysis}

	\paragraph*{} After 19,782 tests producing 286,050 measurements for f-score and 19,782 measurements for accuracy, several notable results emerged.  Most importantly, a small number of method-feature combinations do exist that both provide a reasonable author detection accuracy and have a storage requirement of less than 16MB.  Further, in studying the effects of using the Google Web1T Corpus, Web1T did not provide enough benefit to accuracy to justify its large storage requirement.  This does not mean that Web1T did not have a positive impact on accuracy, especially for the Enron corpus and naive Bayes.  It was also found that Web1T had different impacts on dissimilarly prolific authors than on similarly prolific authors. This chapter provides specific details about usable method-feature combinations and the impacts of Web1T.
	\paragraph*{} There is one notation convention used in this chapter that requires explanation.  The notation Web1T\% refers to the top percentage of the Web1T corpus used as the vocabulary in testing.  For instance, Web1T\% of 1 for OSB3 means that the top 1\% of orthogonal sparse bigrams of distance three (OSB3) were used as the vocabulary.  Web1T\% of 2 for GB3 means that the top 2\% of gappy bigrams of distance three (GB3) are used.  This pattern continues for Web1T\% of 4, 8, and 16 and feature types of 1-grams (GM1), 2-grams (GM2), and 5-grams (GM5).  The only special case is for Web1T\% of 0.  In this case, there was no reference to the Google Web1T Corpus at all in constructing the vocabulary.  The vocabulary is built using any and all tokens found in the training set.

\begin{singlespace}
\section{Most Effective Combination of Classification Methods, Feature Types, and Vocabulary}
\end{singlespace}
	\paragraph*{} Two measurements of effectiveness were used in this thesis: accuracy and f-score.  Since the accuracy for each author is not the focus of this thesis, but rather the overall effectiveness of each classifier, feature type, and vocabulary combination, f-score is averaged, over the set of authors, for each combination.  In each test set, average accuracy was higher than MLE.  Likewise, average f-score was always lower than average accuracy.

	\paragraph*{} At this point, it would be natural to simply compare the highest accuracy for each method-feature-vocabulary combination in the thesis and determine which combination performed best.  This analysis would be flawed.  Due to the underlying data structure in the libLinear model, there is an absolute maximum number, $2^{31}$, of elements allowed.  The libLinear tool creates one element created in its model for each feature-classifier combination.  This means that the number of for each author, there is a dedicated cell for each feature.  The data structure impact for the libLinear tool is array size become the number of authors multiplied by the number of features.  Array size in Java cannot exceed $2^{31}$. This limits the of features that can be used with libLinear for a given number of authors. Figure \ref{fig:FeatureVSsize} shows the value of each feature-vocabulary-group combination.  Cells highlighted in red cannot be used with the LibLinear model.  If only the top $2^{31}$ features from each Web1T\% was used, then large Web1T\% values would have identical features.  For instance, two very large set are OSB3 for Web1T\% of 8 and Web1T\% of 16.  If only the top $2^{31}$ features were used from each of these features sets, then both of these sets, which far exceed $2^{31}$ features, would hold the same $2^{31}$ features.  This would create identical results and provide no additional insight into the true performance of that vocabulary. Therefore, due to the data structure limitation of the libLinear tool, there will be no LibLinear results for feature-author combinations that require an array larger than $2^{31}$ elements in the libLinear model.  
	

\begin{figure}[htbp!]
	\begin{center}
	\centering
	\includegraphics[scale=0.9]{FeatureVSsize}
	\caption{Liblinear Limits Due to Vocabulary Size and Group Size}
	\label{fig:FeatureVSsize}
	\end{center}
\end{figure}


	\paragraph*{}  While libLinear is the chosen SVM tool for this thesis, the classifier method being test is SVM.  For the rest of this chapter, results will be analyzied by method instead of by tool.  For this reason, results will be discussed in terms of SVM and naive Bayes instead of in terms of libLinear and naive Bayes.

	\paragraph*{} The impact of this hard maximum is large vocabularies show a higher accuracy and f-score than smaller vocabularies.  This is not necessarily because the large vocabularies are more effective, but because the larger vocabularies do not have the lower accuracy and f-score outcomes of the large group sizes.  To illustrate this, the top twenty feature-method combinations are show in Table \ref{tab:enron-accuracy-filtered-ranked} for the ENRON E-mail Corpus.  The performance of each SVM OSB3-vocabulary combination is shown in Figure \ref{fig:plot-liblinear-enron-accuracy}. Using Table \ref{tab:twitter-accuracy-filtered-ranked} to evaluate accuracy would lead to a conclusion that SVM OSB3 has the best accuracy and f-score in this thesis.  However, plotting all OSB3 results for each Web1t \%  in \ref{fig:plot-liblinear-enron-accuracy} shows that all OSB3-vocabulary combinations perform along a similar curve.  The Web1T \% $ of 0$ is actually able to perform against all group sizes (5, 10, 25, 50, 75, and 150) and, thus, appears to perform worse than other OSB3s in the table, but clearly performs similarly from Figure \ref{fig:plot-liblinear-enron-accuracy}.  From this example, it becomes clear that simply using the table values in Appendix A through Appendix D provides an insufficient analysis.  A better analysis is provided by examining the plots in Appendix Q through Appendix T.  
	
\begin{figure}[htbp!]
	\centering
	\includegraphics[scale=0.75]{liblinear-enron-avg-by-group_size}
	\caption{Accuracy of SVM OSB3 for the ENRON E-mail Corpus}
	\label{fig:plot-liblinear-enron-accuracy}
\end{figure}
	
	\paragraph*{}It is important to note that this is not an issue for combinations using naive Bayes as a classification method.  However, naive Bayes did not outperform SVM in these tests, so a careful analysis of SVM using the plots in Appendix Q through Appendix T is required.

	\paragraph*{} By examining the plots in Appendix Q through Appendix T, a clear trend emerges that the bootstrapped models, meaning models that made no use of the Web1T corpus as a vocabulary reference) performed similarly for SVM to Web1T vocabularies.  In all cases, the bootstrapped SVM tests are usable for all group sizes.  In this case, a good comparison would be to drop all SVM combinations that are not usable for all group sizes, then compare these remaining SVM tests against all naive Bayes tests.  Since all naive Bayes tests were usable for all group sizes, this makes the comparison fair.
	
	\paragraph*{} After extracting out SVM tests that were not usable against all groups sizes, the highest accuracy method-feature combination show the most accurate results for the ENRON E-mail Corpus in Table \ref{tab:enron-accuracy-filtered-ranked}.  The highest accuracy method-feature combination show the most accurate results for the Twitter Short Message Corpus in Table \ref{tab:twitter-accuracy-filtered-ranked}.
	
	
	\begin{table}[htbp!]
			\begin{center}
			\begin{tabular}{ | r | r | r | r | r | r | r | }
			\hline
			\multicolumn{2}{|c|}{Combinations} & \multicolumn{5}{|c|}{Accuracy}\\
			\hline
			Method & Feature Type & Web1T \% & AVG & MIN & MAX & STDDEV\\ \hline 
			SVM & OSB3 & 0 & 0.8362 & 0.5106 & 0.9732 & 0.1043\\ \hline 
			NB & OSB3 & 16 & 0.8325 & 0.5213 & 0.9823 & 0.0890\\ \hline 
			NB & OSB3 & 8 & 0.8315 & 0.5213 & 0.9714 & 0.0893\\ \hline 
			NB & OSB3 & 4 & 0.8274 & 0.5197 & 0.9587 & 0.0924\\ \hline 
			SVM & GM2 & 0 & 0.8262 & 0.4824 & 0.9753 & 0.1087\\ \hline 
			SVM & GB3 & 0 & 0.8212 & 0.4787 & 0.9835 & 0.1121\\ \hline 
			NB & GB3 & 16 & 0.8195 & 0.5201 & 0.9674 & 0.0947\\ \hline 
			NB & GB3 & 4 & 0.8194 & 0.5340 & 0.9522 & 0.0941\\ \hline 
			SVM & GB3 & 1 & 0.8191 & 0.4731 & 0.9673 & 0.1110\\ \hline 
			SVM & GB3 & 2 & 0.8184 & 0.4765 & 0.9805 & 0.1113\\ \hline 
			NB & GB3 & 8 & 0.8172 & 0.5255 & 0.9782 & 0.0935\\ \hline 
			NB & OSB3 & 1 & 0.8126 & 0.3615 & 0.9574 & 0.1185\\ \hline 
			NB & OSB3 & 2 & 0.8095 & 0.3526 & 0.9575 & 0.1283\\ \hline 
			NB & OSB3 & 0 & 0.8058 & 0.5185 & 0.9592 & 0.0970\\ \hline 
			SVM & GM5 & 16 & 0.7918 & 0.3908 & 0.9676 & 0.1204\\ \hline 
			SVM & GM5 & 8 & 0.7872 & 0.3908 & 0.9513 & 0.1193\\ \hline 
			NB & GB3 & 2 & 0.7857 & 0.4790 & 0.9669 & 0.1166\\ \hline 
			SVM & GM5 & 4 & 0.7755 & 0.3908 & 0.9455 & 0.1241\\ \hline 
			SVM & GM1 & 4 & 0.7742 & 0.4006 & 0.9590 & 0.1212\\ \hline 
			SVM & GM1 & 8 & 0.7740 & 0.4074 & 0.9570 & 0.1223\\ \hline 
			SVM & GM1 & 0 & 0.7735 & 0.3776 & 0.9531 & 0.1222\\ \hline 

			\end{tabular}
		\caption{Highest Accuracy Method-Feature Type Combinations for the ENRON E-mail Corpus}
		\label{tab:enron-accuracy-filtered-ranked}
		\end{center}
	\end{table}
	

	
	\begin{table}[htbp!]
	\begin{center}
			\begin{tabular}{ | r | r | r | r | r | r | r | }
			\hline
			\multicolumn{2}{|c|}{Combinations} & \multicolumn{5}{|c|}{Accuracy}\\
			\hline
			Method & Feature Type & Web1t \% & AVG & MIN & MAX & STDDEV\\ \hline 
			NB & OSB3 & 0 & 0.5525 & 0.2320 & 0.8164 & 0.1339\\ \hline 
			NB & GB3 & 16 & 0.5327 & 0.2216 & 0.8216 & 0.1351\\ \hline 
			NB & GB3 & 4 & 0.5271 & 0.2190 & 0.8546 & 0.1375\\ \hline 
			NB & GB3 & 8 & 0.5256 & 0.2176 & 0.8474 & 0.1362\\ \hline 
			NB & GB3 & 2 & 0.5249 & 0.2186 & 0.7823 & 0.1324\\ \hline 
			SVM & GM2 & 4 & 0.5228 & 0.1809 & 0.8210 & 0.1477\\ \hline 
			NB & GB3 & 1 & 0.5204 & 0.2148 & 0.8125 & 0.1319\\ \hline 
			NB & GB3 & 0 & 0.5203 & 0.1973 & 0.8021 & 0.1389\\ \hline 
			SVM & GM2 & 1 & 0.5197 & 0.1882 & 0.8454 & 0.1483\\ \hline 
			SVM & GM1 & 8 & 0.5187 & 0.1743 & 0.9026 & 0.1525\\ \hline 
			SVM & GM2 & 2 & 0.5186 & 0.1830 & 0.8232 & 0.1495\\ \hline 
			SVM & GM1 & 1 & 0.5159 & 0.1768 & 0.8211 & 0.1494\\ \hline 
			SVM & GM1 & 4 & 0.5149 & 0.1874 & 0.8546 & 0.1485\\ \hline 
			SVM & GM1 & 0 & 0.5141 & 0.1802 & 0.8089 & 0.1485\\ \hline 
			NB & GM1 & 0 & 0.5140 & 0.1247 & 0.7714 & 0.1631\\ \hline 
			SVM & GM1 & 16 & 0.5134 & 0.1865 & 0.8324 & 0.1483\\ \hline 
			SVM & GM1 & 2 & 0.5131 & 0.1818 & 0.8966 & 0.1487\\ \hline 
			SVM & GM5 & 1 & 0.4768 & 0.1398 & 0.8362 & 0.1521\\ \hline 
			NB & GM2 & 0 & 0.4750 & 0.1630 & 0.7890 & 0.1406\\ \hline 
			NB & OSB3 & 2 & 0.4739 & 0.1790 & 0.7734 & 0.1370\\ \hline 
			NB & OSB3 & 8 & 0.4707 & 0.1787 & 0.7790 & 0.1373\\ \hline 

			\end{tabular}
		\caption{Highest Accuracy Method-Feature Type Combinations for the Twitter Short Message Corpus}
		\label{tab:twitter-accuracy-filtered-ranked}
		\end{center}	
	\end{table}
	
	
	\paragraph*{} From Table \ref{tab:enron-accuracy-filtered-ranked} orthogonal sparse bigrams and gappy bigrams perform very well overall, with a traditional bigram making an entry at number five.  The best performing method-feature combination is SVM OSB3 with a Web1t\% of 0.  The next three combinations are naive Bayes classifiers using OSB3 with large Web1T\% vocabulary sizes.  The results are similar for gappy bigrams, but at a reduced accuracy of approximately one percent.
	
	\paragraph*{} From Table \ref{tab:twitter-accuracy-filtered-ranked}, the top performing method-feature combination is naive Bayes OSB3 with a Web1T \% of 0.  The next four positions are filled with gappy bigrams with sizable Web1T\% vocabularies.  Why Twitter responds better to naive Bayes as opposed to e-mail responding better to SVM is left to future work.
	
	\paragraph*{} While the above table shows the best performing, accuracy is not always a solid measure of classification effectiveness.  A better measure is f-score.  As shown repeatedly by the tables in Appendix A through Appendix D, the relative performance of average f-score matched the relative performance of accuracy for each test set.  In all cases, f-score was lower than the average accuracy.  Even more telling about the results is every test set shows a minimum f-score of 0.  That means that at least one author had an f-score of zero in each test.  This accounts for the high standard deviation for f-scores across all tests.  For f-scores of approximately 0.65 the standard deviation was approximately 0.25.
	
	\paragraph*{} An examination of the confusion matrices for each test can provide insight into whether there was a "poison" author that never got selected or if there was an author who was a selection "magnet" always getting too many selections for documents.  Due to the large number of confusions matrices in this thesis ( nearly 19,782 confusion matrices created from 57 tests * 3 size groupings * 6 vocabulary sizes * 5 feature types * 2 corpora * 2 methods -  738 unusable SVM tests) the confusions matrices are not presented in this thesis, but are archived by the NPS Natural Language Processing lab in comma separated value files.

\begin{singlespace}
\section{Impact of Author Relative Prolificity on Classifier Effectiveness}
\end{singlespace}
	\paragraph*{} While identifying the best accuracy results for method-feature combinations is important, these results could mask a weakness in the method-feature combinations.  Does the relative prolificity of each author impact the results?  To answer this question, the tests in this thesis were conducted in three groupings: small-to-large, small-and-large, and random.  As explained fully in Chapter 3, these groupings were based on a rank-ordering by size for each author's total document collection.  For small-to-large, the least prolific authors are grouped together, while the most prolific authors are grouped together. The idea behind the small-to-large group is to keep the difference in total documents size between the authors to a minimum. For small-and-large, the opposite idea is employed.  The smallest authors are combined with the largest authors using a bucket strategy.  Each bucket contains rank-ordered by size authors of similar size.  One author is picked from each bucket to provide a maximum variety of author document collections sizes.  In the random group, the authors are grouped together using a pseudo-random number generator, where each author has been assigned a number.
	\paragraph*{} The results of testing in this thesis for accuracy and f-score, broken out by small-to-large, small-and-large, and random are given in Appendix E through Appendix H.  The results from Appendix E, SVM Results for the ENRON E-mail Corpus, show the accuracy for small-to-large is always lower than the accuracy for small-and-large and random.  However, the f-score for small-to-large is always higher than the f-score for small-and-large and random.  This result shows how accuracy is dominated by the MLE author, since allowing a more prolific author into a group with less prolific authors tends to raise accuracy, but hurts f-score. To illustrate the effect of author prolificity on accuracy and f-score Table \ref{tab:enron-stl-confusionmatrix} shows the confusion matrix for a small-to-large grouping of size 10 for GB3, Web1T\%=0.  Table \ref{tab:enron-sal-confusionmatrix} shows the confusion matrix for a small-and-large grouping of size 10 for GB3, Web1T\%=0. 
	
	\begin{table}[htbp!]
	\begin{center}
			\begin{tabular}{ | c | r | r | r | r | r | r | r | r | r| r | r |}
			\cline{3-12}
			\multicolumn{2}{c}{} & \multicolumn{10}{|c|}{Label}\\ \cline{3-12}
			\multicolumn{2}{c|}{} & 11 & 111 & 119 & 14 & 146 & 15 & 48 & 60 & 71 & 91\\ \hline 
			\multirow{10}{*}{\begin{sideways}Truth\end{sideways}} & 11 & 0 & 0 & 0 & 0 & 0 & 0 & 2 & 0 & 1 & 0\\ \cline{2-12}
			& 111 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ \cline{2-12} 
			& 119 & 0 & 0 & 8 & 1 & 0 & 0 & 0 & 0 & 0 & 6\\ \cline{2-12} 
			& 14 & 0 & 0 & 0 & 4 & 0 & 0 & 0 & 0 & 0 & 10\\ \cline{2-12} 
			& 146 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 1\\ \cline{2-12} 
			& 15 & 0 & 0 & 0 & 1 & 0 & 4 & 1 & 0 & 0 & 4\\ \cline{2-12} 
			& 48 & 0 & 0 & 0 & 2 & 0 & 0 & 9 & 0 & 0 & 2\\ \cline{2-12} 
			& 60 & 0 & 0 & 2 & 0 & 0 & 0 & 1 & 4 & 0 & 2\\ \cline{2-12} 
			& 71 & 0 & 0 & 0 & 2 & 0 & 0 & 0 & 0 & 0 & 4\\ \cline{2-12} 
			& 91 & 0 & 0 & 0 & 2 & 0 & 0 & 1 & 0 & 0 & 17\\ \hline
	\end{tabular}
		\caption{Confusion Matrix for Small-To-Large Grouping, Feature Type: GB3, Group Size: 10, Web1T\%: 0}
		\label{tab:enron-stl-confusionmatrix}
		\end{center}	
	\end{table}
	
	\begin{table}[htbp!]
	\begin{center}
			\begin{tabular}{ | c | r | r | r | r | r | r | r | r | r| r | r |}
			\cline{3-12}
			\multicolumn{2}{c}{} & \multicolumn{10}{|c|}{Label}\\ \cline{3-12}
			\multicolumn{2}{c|}{} & 11 & 113 & 47 & 49 & 58 & 75 & 76 & 86 & 88 & 95\\ \hline 
			\multirow{10}{*}{\begin{sideways}Truth\end{sideways}}& 11 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 2 & 0\\ \cline{2-12} 
			& 113 & 0 & 203 & 43 & 23 & 3 & 6 & 0 & 4 & 19 & 0\\ \cline{2-12} 
			& 47 & 0 & 7 & 2510 & 2 & 4 & 2 & 0 & 3 & 61 & 0\\ \cline{2-12}
			& 49 & 0 & 16 & 52 & 1180 & 2 & 6 & 0 & 2 & 48 & 1\\ \cline{2-12} 
			& 58 & 0 & 1 & 16 & 2 & 508 & 0 & 0 & 0 & 7 & 0\\ \cline{2-12} 
			& 75 & 0 & 5 & 19 & 4 & 0 & 338 & 0 & 1 & 16 & 0\\ \cline{2-12} 
			& 76 & 0 & 0 & 1 & 3 & 0 & 0 & 9 & 0 & 1 & 0\\ \cline{2-12} 
			& 86 & 0 & 14 & 12 & 14 & 2 & 9 & 0 & 36 & 15 & 0\\ \cline{2-12} 
			& 88 & 0 & 11 & 129 & 12 & 1 & 7 & 0 & 0 & 277 & 1\\ \cline{2-12} 
			& 95 & 0 & 4 & 2 & 7 & 3 & 2 & 0 & 1 & 9 & 4\\ \hline
	\end{tabular}
		\caption{Confusion Matrix for Small-And-Large Grouping, Feature Type: GB3, Group Size: 10, Web1T\%: 0}
		\label{tab:enron-sal-confusionmatrix}
		\end{center}	
	\end{table}
	
	\paragraph*{} Table \ref{tab:enron-stl-confusionmatrix} represents a group of similarly prolific authors.  One author, author 91, not only has the highest number of true positives, 17, but has a large number of false positives.  The combined false positives for all other authors is 21, compared to author 91's 29 false positives.  That counts as 29 false negatives spread across the other 9 authors, impacting their false negative value.  For calculating f-score, a higher false negative rate decreases recall and, since true positives remain constant, false positives fall, increasing precision.  In the small-to-large grouping, one author has very few false positives, creating a high precision.  The other authors end up with a high recall.  As the f-score for each author is average for the group, these unbalanced numbers drive the f-score higher while maintaining a lower accuracy.
	\paragraph*{} Table \ref{tab:enron-sal-confusionmatrix} represents a group of dissimilarly prolific authors.  In this grouping, one author does not dominate the number of false positives.  This more evenly spread set of false positives and false negatives keeps the overall f-score lower, while maintaining a higher accuracy.  The bottom line is the high outlier precision score for one author in the small-to-large group gives a higher f-score, but lower accuracy.  A median measurement of f-score might provide a better picture of overall f-score behavior than an average f-score.
	\paragraph*{} The other issue that arises from the f-score average is the small-to-large f-score has a smaller standard deviation than the small-and-large f-score.  This points to a tighter grouping of values.  This arises from all but one author having similar f-score values.  The small-and-large group has no single outlier f-score to drag the f-score higher, but the values do have greater variation among all points.
	\paragraph*{}The above paragraphs make use of a cursory examination of the behavior of author detection due to author prolificity.  An in-depth statistical analysis of the difference between the author groupings is warranted as future work.  The goal of using these different groupings was to ensure that the tools chosen in this thesis behaved predictably with respect to varying author prolificity within a detection group.  To examine that behavior, plots of accuracy, average f-score, MLE, precision, and recall for each method-feature combination across all usable Web1T\% vocabularies is included in Appendix Q through Appendix U.  To illustrate that the impact of author prolificity is predictable across method-feature combinations and corpora, Figure \ref{fig:liblinear-enron-GB3-10-measures} and Figure \ref{fig:liblinear-twitter-GB3-10-measures} are shown as representative samples of overall classifier and corpora results.
	
\begin{figure}[htbp!]
	\begin{center}
	\centering
	\includegraphics[scale=1.00]{figure_liblinear_enron_grouping_compare}
	\caption{SVM Limits Due to Vocabulary Size and Group Size}
	\label{fig:liblinear-enron-GB3-10-measures}
	\end{center}
\end{figure}

\begin{figure}[htbp!]
	\begin{center}
	\centering
	\includegraphics[scale=1.00]{figure_liblinear_twitter_grouping_compare}
	\caption{SVM Limits Due to Vocabulary Size and Group Size}
	\label{fig:liblinear-twitter-GB3-10-measures}
	\end{center}
\end{figure}
	
	\paragraph*{} From Figure \ref{fig:liblinear-enron-GB3-10-measures} some trends become apparent.  As the small-to-large graph for the Enron corpus moves from left to right, the accuracy, f-score, precision, and recall all increase in tight agreement.  This correlates to the wide variation in prolificity between the least prolific group on the far left, file 000\_009, and the last file on the far right, file 140\_149.  In the Enron corpus, the least prolific author's document total size is measured in a few kilobytes where the most prolific author's document total size is measured in megabytes.  Most striking is that the trend holds for both SVM and naive Bayes.  Also, with a group size of 10, the most prolific authors have a high accuracy, high f-score, high precision, and high recall.  The impact of prolificity is predictable and significant for the Enron Corpus.
	\paragraph*{} The results for the Enron corpus small-and-large group are largely flat as the graph moves from left to right.  This shows that in a mixed group of varying prolificity, both SVM and naive Bayes maintain fairly consistent results.  Clearly, having an author who is significantly more prolific than other authors in his detection group hurts the average f-score for that group while raising the accuracy.  This rise in accuracy is not a good indicator of improved performance.  For the Enron E-mail Corpus, prolific authors are more detectable than less prolific authors, even in the presence of other prolific authors.
	
	\subsection{Cumulative Distribution of Authors Over F-Scores Due to Grouping}
	\paragraph*{} In the Enron small-and-large figures, precision and accuracy are close in value where f-score and recall are always close in value.  The accuracy and precision values are also always above the f-score and recall values.  Investigation into the underlying reasons for this pattern warrants future work in an in-depth statistical analysis of the effects of grouping on author detection.
	\paragraph*{} The story from Figure \ref{fig:liblinear-twitter-GB3-10-measures} is markedly different than the story from Figure \ref{fig:liblinear-enron-GB3-10-measures}.  All results are lower for the Twitter Short Message Corpus than for the Enron E-mail Corpus, as indicated by the top value on for graphs in Figure \ref{fig:liblinear-twitter-GB3-10-measures} being 0.7 versus 1.0 for Figure \ref{fig:liblinear-enron-GB3-10-measures}.  The relative flatness of measures in the Twitter corpus compared to the Enron corpus can be explained by the difference in relative sizes of an author in the Twitter corpus and an author in the Enron corpus.  The most prolific author in the Twitter corpus has only 15.2KB of text as opposed to 2.5MB for the most prolific Enron author.  Future work of gathering a larger Twitter corpus of original, not re-tweeted, short messages could supply a similar size and variation of the Enron corpus.
	
	\paragraph*{} The further illustrate the impact of grouping similarly profilic, dissimilarly prolific, and randomly prolific authors together, cumulative distribution graphs were constructed for four scenarios: SVM for Enron in Figure \ref{fig:plot-tiled-cdf-summary-liblinear-enron-gb3-10}, naive Bayes for Enron in Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-gb3-10}, SVM for Twitter in Figure \ref{fig:plot-tiled-cdf-summary-liblinear-twitter-gb3-10}, and naive Bayes for Twitter in Figure \ref{fig:plot-tiled-cdf-summary-nb-twitter-gb3-10}.  Each of these plots are displayed as six panels in one figure.  Each panel represent a different Web1T\% for that method-corpus combination.  The panel Web1T\% values are, from upper left to lower right by row, 0, 1, 2, 4, 8, and 16.  Each panel has three lines plotted as the cumulative distribution of authors over f-score.  The f-scores in these panels are per-author, not averaged, and not weighted f-scores.  For the sake of consistency, all four figures use GB3 as the feature type and a group size of 10.  The graphs show are representative of all feature types (GM1, GM2, GM5, GB3, OSB3). Group size has a significant impact on the shape and position of the graphs.  The impact of group size on the will be demonstrated in the next subsection. There are some blank panels in the graphs.  Blank graphs occurs when the number of authors coupled with the number of types exceeds $2^{31}$ elements and cannot fit into the array used by libLinear model.
	
	\paragraph*{} The characteristics being examined in these cumulative distribution graphs how are the lines curved, how closely the lines are grouped, and how far the lines are to the left or right.  
	\begin{itemize}
		\item For curvature, a line curving to the bottom right shows that a large number of authors have higher f-scores.  A line curving to the upper left corner show that a larger number of authors have lower f-scores.  A line curving to the bottom right demonstrates a better performing method-feature combination.  
		\item For close grouping of lines, the closer the lines are grouped together, the more negligible the effect of author prolficity has on f-score.  For instance, if the small-to-large line curves to the lower right while the small-and-large line curves to the upper left, the having authors of dissimilar size had a detrimental effect on author f-score.  More closely grouped lines demonstrates a better performing method-feature combination because that combination performs more consistently across groupings by author prolificity.  
		\item In examining the position of the lines to the left or right, lines positioned further to the right indicated more authors with a higher f-score, even at the bottom of the curve.  For instance, a line starting at a f-score of 0.0 shows that at least one author had a f-score of 0.0.  A line starting at 0.4 show the worst f-score for any author was 0.4, which demonstrates a a better performing method-feature combination.
	\end{itemize}
	
	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-liblinear-enron-gb3-10-crop}
		\caption{plot-tiled-cdf-summary-liblinear-enron-gb3-10}
		\label{fig:plot-tiled-cdf-summary-liblinear-enron-gb3-10}
		\end{center}
	\end{figure}
	
	\paragraph*{}  The panels in Figure \ref{fig:plot-tiled-cdf-summary-liblinear-enron-gb3-10} shows a representative set of curves for all SVM tests on the Enron E-Mail Corpus.  Looking at the first panel, the curvature of all three lines, small-to-large, small-and-large, and random are all of similar shape.  That shape curves down and to the right. The small-to-large curve slightly outperforms the small-and-large and random curve up to a f-score of 0.7. This similarity in curvature is consistent as the Web1T\% increase through the next five panels. All three lines are grouped closely together.  The close grouping is consistent through the next five panels. The left to right positioning of the curves is nearly identical.  This positioning does not shift as the Web1T\% increases.
	\paragraph*{} These panels show that the results of SVM on Enron are consistent and generally positive with or without Web1T\%.  It also shows that SVM performance against Enron is consistent for both similarly and dissimilarly prolific authors.
	
	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.6]{plot-tiled-cdf-summary-nb-enron-gb3-10-crop}
		\caption{plot-tiled-cdf-summary-nb-enron-gb3-10}
		\label{fig:plot-tiled-cdf-summary-nb-enron-gb3-10}
		\end{center}
	\end{figure}
	
	\paragraph*{}  The panels in Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-gb3-10} shows a representative set of curves for all naive Bayes tests on the Enron E-Mail Corpus.  Looking at the first panel, the curvature of the small-to-large line is down and to the right.  The small-and-large line and the random line curve up and to the left.  This shows the small-to-large line performing significantly better than the other two lines.  This pattern is not consistent moving from the first panel, Web1T\% of 0, to the second panel, Web1T\% of 1.  In the second panel the small-and-large line and the random line both curve down and to the right.  At this point all three lines are grouped closer together, but not as closely as in SVM for Enron.  The grouping varies slightly through the next four panels with small-to-large alway outperforming small-and-large and random. The left to right positioning of the curves is nearly identical for the second through sixth panels.  The position on the small-and-large line and the random line improved from the first panel to the second panel.  
	\paragraph*{} There are three observations from the naive bayes for Enron panels in Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-gb3-10}, first moving from a bootstrap naive bayes using Laplace plus one smoothing to a Web1T\% smoothing greatly improves the performance of the small-and-large and random lines without any appreciable change to the small-to-large line.  This shows that Web1T\% has is useful as a smoothing tool for naive bayes for the Enron Email corpus.  Second, there is no further significant performance improvement to any line as the Web1T\% increase beyond 1\%.  This implies that only the most common terms in the Web1T corpus have a significant impact on smoothing.  Third, using naive bayes, f-score performas similary for small-to-large with Web1T or without Web1T.  This speaks to the power of having similarly sized speakers in the same author detection group.
	
	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-liblinear-twitter-gb3-10-crop}
		\caption{plot-tiled-cdf-summary-liblinear-twitter-gb3-10}
		\label{fig:plot-tiled-cdf-summary-liblinear-twitter-gb3-10}
		\end{center}
	\end{figure}
	
	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-nb-twitter-gb3-10-crop}
		\caption{plot-tiled-cdf-summary-nb-twitter-gb3-10}
		\label{fig:plot-tiled-cdf-summary-nb-twitter-gb3-10}
		\end{center}
	\end{figure}
	
		\paragraph*{}  The panels in Figure \ref{fig:plot-tiled-cdf-summary-liblinear-twitter-gb3-10} shows a representative set of curves for all SVM tests on the Twitter Short Message Corpus.  The panels in Figure \ref{fig:plot-tiled-cdf-summary-liblinear-twitter-gb3-10} shows a representative set of curves for all naive Bayes test on the Twitter Short Message Corpus. Both figures are nearly identical.  Looking at the first panel of both figures, the curvature of all three lines, small-to-large, small-and-large, and random are all of similar shape.  That shape curves is an "S" shape showing that there are few authors with low f-scores and few authors with high f-scores. No curve regularly outperforms the others. This similarity in curvature is consistent as the Web1T\% increase through the next five panels. All three lines are grouped closely together.  The close grouping is consistent through the next five panels. The left to right positioning of the curves is nearly identical except that introducing a Web1T\% of 1 into \ref{fig:plot-tiled-cdf-summary-liblinear-twitter-gb3-10} shifts the line further to the right, improving overall performance.  This positioning does not shift as the Web1T\% increases.
		\paragraph*{} These panels show that the results of SVM and naive Bayes on Twitter are consistent and generally mediocre with or without Web1T\%.  It also shows that SVM performance against Twitter is consistent for both similarly and dissimilarly prolific authors.

\subsection{Cumulative Distribution of Authors Over F-Score Due to Group Sizes}
\paragraph*{} Figures \ref{fig:plot-tiled-cdf-summary-liblinear-enron-GB3-ALL-0}, \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0}, \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1}, {fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1}, and {fig:plot-tiled-cdf-summary-nb-twitter-GB3-ALL-0} are representative examples of the impact of changing group size on authors being grouped by prolificity.  There are six panels in each figure.  The panels progress from upper left to bottom right through group sizes 5, 10, 25, 50, 75, and 150.  All of these figures except Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1} display a Web1T\% of 0. Figure ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1} displays a Web1T\% of 1 to present the difference in general shape between naive Bayes against Enron for both Web1T\% of 0 (Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0}) and 1 (Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1}).

	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-liblinear-enron-GB3-ALL-0-crop}
		\caption{plot-tiled-cdf-summary-liblinear-enron-GB3-ALL-0}
		\label{fig:plot-tiled-cdf-summary-liblinear-enron-GB3-ALL-0}
		\end{center}
	\end{figure}

\paragraph*{} Figure \ref{fig:plot-tiled-cdf-summary-liblinear-enron-GB3-ALL-0} shows the typical progression as group size increase from an initial value of 5 to a final value of 150.  The curvature of all three lines shifts from curving down and right to up and left.  None of the feature-group size combination ever curve left and up past a basically straight line.  The grouping of the lines gets tighter as the group size increases.  Specifically, the small-to-large curve gets worse at a faster rate as the group sizes increase, causing the small-to-large line to decrease the distance between it and the small-and-large and random lines.  This shows that group size impacts the small-to-large line more than the small-and-large and random lines.  The left to right position of the endpoints of all three lines remain relatively fixed through all group sizes.  This shows that the worst and best f-scores remains relatively constant through the group sizes while f-scores in the middle f-score authors worsens.
	
	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-nb-enron-GB3-ALL-0-crop}
		\caption{plot-tiled-cdf-summary-nb-enron-GB3-ALL-0}
		\label{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0}
		\end{center}
	\end{figure}
	
	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-nb-enron-GB3-ALL-1-crop}
		\caption{plot-tiled-cdf-summary-nb-enron-GB3-ALL-1}
		\label{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1}
		\end{center}
	\end{figure}

\paragraph*{} Figures \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0} and {fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1} both show the cumulative distribution of authors over f-score for naive Bayes against Enron.  The two plots start with different shapes.  The first panel of Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0} start with with separation between the small-to-large line and the small-and-large lines.  The small-to-large curvature is down and right where the small-and-large curve is up and left.  As group size increases, the curvature of all lines increases, but not at the same rate.  The small-to-large line closes the gap between lines until all lines are merged in the last panel, group size of 150.  It makes sense that the last panel shows all lines on top of each other because all 150 author are included in all three lines.  If these lines show different curvature, that would indicate a problem with the methodogy, since the only difference between the training and test sets of these three lines is the order that documents are read by the classifier.  For group sizes of 5 through 75, each line contains groups unique combinations of authors.
\paragraph*{} Figure{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1} begins with all three line cloesly grouped.  Just like in Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0}, the curvature of all three lines progresses from down and right to more up and left as group size increases.  The grouping of the three lines becomes closer as group size increases with all three lines merging at a group size of 150. However, the group size of 150 for Figure {fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0} is essentially a diagonal line in Figure {fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-1} where it is a up and left curve for Figure \ref{fig:plot-tiled-cdf-summary-nb-enron-GB3-ALL-0}.  This indicates that naive Bayes benefits from the use of Web1T\% of 1 over naive Bayes with a Web1t\% of 0.  This result is typical of all the naive Bayes against Enron cumulative distribution graphs.  This begs the question of whether Web1T smoothing performs better than other smoothing techniques such as Witten-Bell or Good-Turing.  Witten-Bell and Good-Turing do not bring the large storage requirement of Web1T smoothing, but may produce similar results.  Determining this result is left for future work.

	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-liblinear-twitter-GB3-ALL-0-crop}
		\caption{plot-tiled-cdf-summary-liblinear-twitter-GB3-ALL-0}
		\label{fig:plot-tiled-cdf-summary-liblinear-twitter-GB3-ALL-0}
		\end{center}
	\end{figure}

\paragraph*{}

	\begin{figure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[angle=270, scale=0.75]{plot-tiled-cdf-summary-nb-twitter-GB3-ALL-0-crop}
		\caption{plot-tiled-cdf-summary-nb-twitter-GB3-ALL-0}
		\label{fig:plot-tiled-cdf-summary-nb-twitter-GB3-ALL-0}
		\end{center}
	\end{figure}
	For Twitter GM2 with naive Bayes, applying Web1T\% of 1 makes STL worse, but leaves SAL and RAN intact.  Additional Web1T\% makes the damage to STL less severe, but does not get back to STL results of Web1T\% of 0.
	
		\paragraph*{} Impact of CDF? Twitter was barely on the scene in 2006 when the Google Web1T snapshot was taken.  There was no significant Twitter corpus for Google to crawl.  Twiiter language has evolved significantly since its inception and may differ appreciably from standard English or even standard web verbiage.  Could a new Web1T built from a Google database that has crawled Twitter term................

\begin{singlespace}
\section{Storage Requirements for Combinations of Classification Methods, Feature Types, and Vocabulary}
\end{singlespace}
	\paragraph*{} While the effectiveness of the method-feature combinations are important, these tools are of no use on a mobile device unless the tool can actually fit on the disk and within the RAM on the mobile device.  An important fact about determining the size of classifier models is that the size of the model in RAM does not equal the size of the model when written to a file.  For instance, a Java long (primitive) of 1 uses 8 bytes of RAM, but is represented in a file using only 4 bytes.  Similarly, there is a disparity between the UTF-8 values byte size on disk and the object representation in RAM for many Java objects.  This is why heap size could not be used as an accurate measurement of model size.
	\paragraph*{}To determine if any of these method-feature combinations will fit on a mobile device, a few combinations had exhaustive outputs of their model sizes computed.  After determining that the standard deviation for models with a vocabulary size greater than a Web1T\% of 0 was trivial, only a small sample of the remaining method-feature combinations were computed.  Due to the large size of many models, only one model size was calculated for many method-feature combinations.  
	\paragraph*{} Actually writing out these models to disk would have been extremely time consuming and a load on the already taxed Hamming High Performance Cluster.  To conduct the size measurements, the SVM models were written to a Java ByteArrayOutputStream.  Once the write was complete, the size of the ByteArrayOutputStream buffer was measured.  The worked well for models smaller than 2GB.  Models larger than 2GB caused the ByteArrayOutputStream to be "full" since the index for an ByteArrayOutputStream is limited to $2^{31}$ elements and each element in that array is a byte.  For any model larger than 2GB, the size for that model was not recorded and thus has no size record in Appendix M through Appendix P nor a score in the scoring tables in Appendix I through Appendix L.
	\paragraph*{} What constitutes a storage requirement for the method-feature combinations in this thesis depends on the vocabulary size and method used.  A Web1T\% of 0 in SVM requires no keys.mph or signature file, but does require a sizable vocabulary map.  For naive Bayes, a Web1T\% of 0 does not require a keys.mph file, signature file, count file, nor logprobs file.  However a sizable vocabulary map is needed.  The sizes for each combination's keys.mph, signature, counts, logprobs, and average author size are included with totals in Appendix M through Appendix P.  To provide an intuition on the magnitude of sizes involved, Table \ref{tab:sample_vocab_reference_sizes} shows sizes for keys.mph, signature, counts, logprobs, and vocabmap for a few method-feature combinations.  Table \ref{tab:sample_vocab_reference_sizes} shows only the vocabmap size for the Web1T\% of 0.  This is because Web1T\% of 0 does not use keys.mph, signature, counts, or logprobs references, but does create it own vocabulary map.  Complete size tables are provided in Appendix M through Appendix P.
	
	\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | r | r | }
			\hline
			 &  &  & \multicolumn{6}{|c|}{Size (MB)}\\ \cline{4-9}
			\begin{sideways}Method\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Web1T\%\end{sideways} & \begin{sideways}keys.mph\end{sideways} & \begin{sideways}signature\end{sideways} & \begin{sideways}counts\end{sideways} & \begin{sideways}logprobs\end{sideways} & \begin{sideways}vocabmap\end{sideways} & \begin{sideways}Total\end{sideways}\\ \hline 
			SVM & GB3 & 0 & 0.00 & 0.00 & 0.00 & 0.00 & 54.31 & 54.31\\ \hline 
			SVM & GB3 & 1 & 3.21 & 12.11 & 0.00 & 0.00 & 0.00 & 15.32\\ \hline 
			SVM & GB3 & 2 & 6.41 & 24.22 & 0.00 & 0.00 & 0.00 & 30.63\\ \hline 
			SVM & GB3 & 4 & 12.82 & 48.44 & 0.00 & 0.00 & 0.00 & 61.27\\ \hline 
			SVM & GB3 & 8 & 25.64 & 96.89 & 0.00 & 0.00 & 0.00 & 122.53\\ \hline 
			SVM & GB3 & 16 & 51.31 & 193.85 & 0.00 & 0.00 & 0.00 & 245.15\\ \hline 
			SVM & GM1 & 0 & 0.00 & 0.00 & 0.00 & 0.00 & 1.40 & 1.40\\ \hline 
			SVM & GM1 & 1 & 0.07 & 0.27 & 0.00 & 0.00 & 0.00 & 0.34\\ \hline 
			SVM & GM1 & 2 & 0.14 & 0.54 & 0.00 & 0.00 & 0.00 & 0.69\\ \hline 
			SVM & GM1 & 4 & 0.29 & 1.09 & 0.00 & 0.00 & 0.00 & 1.37\\ \hline 
			SVM & GM1 & 8 & 0.58 & 2.17 & 0.00 & 0.00 & 0.00 & 2.75\\ \hline 
			SVM & GM1 & 16 & 1.15 & 4.35 & 0.00 & 0.00 & 0.00 & 5.50\\ \hline 
			NB & GB3 & 0 & 0.00 & 0.00 & 0.00 & 0.00 & 54.31 & 54.31\\ \hline 
			NB & GB3 & 1 & 3.21 & 12.11 & 48.44 & 48.44 & 0.00 & 112.20\\ \hline 
			NB & GB3 & 2 & 6.41 & 24.22 & 96.88 & 96.88 & 0.00 & 224.39\\ \hline 
			NB & GB3 & 4 & 12.82 & 48.44 & 193.78 & 193.78 & 0.00 & 448.83\\ \hline 
			NB & GB3 & 8 & 25.64 & 96.89 & 387.55 & 387.55 & 0.00 & 897.64\\ \hline 
			NB & GB3 & 16 & 51.31 & 193.85 & 775.39 & 775.39 & 0.00 & 1795.94\\ \hline 
			NB & GM1 & 0 & 0.00 & 0.00 & 0.00 & 0.00 & 1.40 & 1.40\\ \hline 
			NB & GM1 & 1 & 0.07 & 0.27 & 1.09 & 1.09 & 0.00 & 2.52\\ \hline 
			NB & GM1 & 2 & 0.14 & 0.54 & 2.17 & 2.17 & 0.00 & 5.04\\ \hline 
			NB & GM1 & 4 & 0.29 & 1.09 & 4.35 & 4.35 & 0.00 & 10.07\\ \hline 
			NB & GM1 & 8 & 0.58 & 2.17 & 8.70 & 8.70 & 0.00 & 20.14\\ \hline 
			NB & GM1 & 16 & 1.15 & 4.35 & 17.40 & 17.40 & 0.00 & 40.29\\ \hline
		\end{tabular}
		\caption{Sample of Vocabulary Reference File Sizes}
		\label{tab:sample_vocab_reference_sizes}
		\end{center}
	\end{table}
	

	\paragraph*{} It is quickly apparent from this table that few of these files could be loaded into the RAM of a 16MB Dalvik VM.  If these files were to be used, they would have to be read directly from the microSD card, which is an expensive operation compared to reading from RAM.  A more thorough discussion of method-feature combinations is discussed in the last section of this chapter.
	
	\paragraph*{} Apart from the vocabulary references needed for the method-feature combinations, each method-feature combination produces a different authors model size.  Unlike the vocabulary reference files, the authors model file sizes vary greatly.  The model constructed for SVM consists of an array populated with the support vector values for each author.  The model for naive Bayes consists of a Java hashmap.  That hashmap has an Integer object for a key and a Double object for its value.  The Integer object is the mapped integer value for a given token.  The Double object is the probability for that token during the training process.
	
	\paragraph*{} The impact of authors model size for a mobile device is important. Even if the vocabulary reference files can be accommodate by a mobile device, a large authors model can push the storage requirement beyond the 16MB Dalvik VMs capability or even the capacity of common microSD cards.  It is important to note here that size on a file only provides a relative indicator of size in RAM for a given method-feature combination.  Actually measuring the impact of Dalvik VM in terms of RAM used versus storage requirements is left to future work as this study involves how model referencing is handled and how values on the file are converted to objects in memory. Table \ref{tab:sample_authors_model_sizes} shows a sample of author sizes for both SVM and naive Bayes authors models.  A complete list of average authors models sizes is provided in Appendix M through Appendix P.
	
	\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | r | r | }
			\hline
			 &  &  &  &  & \multicolumn{4}{|c|}{Size (MB)}\\ \cline{6-9}
			\begin{sideways}Corpus\end{sideways} & \begin{sideways}Method\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Group Size\end{sideways} & \begin{sideways}Web1T\%\end{sideways} & \begin{sideways}AVG\end{sideways} & \begin{sideways}MIN\end{sideways} & \begin{sideways}MAX\end{sideways} & \begin{sideways}STDDEV\end{sideways}\\ \hline
		enron & SVM & OSB3 & 5 & 0 & 15.254 & 8.020 & 31.368 & 5.840\\ \hline 
		enron & SVM & OSB3 & 5 & 1 & 259.320 & 211.231 & 262.991 & 7.944\\ \hline 
		enron & SVM & OSB3 & 5 & 2 & 521.039 & 422.022 & 530.023 & 11.188\\ \hline 
		enron & SVM & OSB3 & 5 & 4 & 1031.477 & 844.102 & 1039.616 & 26.316\\ \hline 
		enron & NB & OSB3 & 5 & 0 & 5.328 & 0.068 & 34.479 & 7.090\\ \hline 
		enron & NB & OSB3 & 5 & 1 & 8.528 & 0.075 & 54.680 & 11.243\\ \hline 
		enron & NB & OSB3 & 5 & 2 & 8.544 & 0.075 & 54.939 & 11.286\\ \hline 
		enron & NB & OSB3 & 5 & 4 & 8.550 & 0.075 & 55.054 & 11.305\\ \hline 
		enron & NB & OSB3 & 5 & 8 & 8.553 & 0.075 & 55.100 & 11.314\\ \hline 
		enron & NB & OSB3 & 5 & 16 & 8.554 & 0.075 & 55.121 & 11.317\\ \hline 
		twitter & SVM & GM1 & 5 & 0 & 0.088 & 0.076 & 0.108 & 0.007\\ \hline 
		twitter & SVM & GM1 & 5 & 1 & 1.568 & 1.546 & 1.614 & 0.013\\ \hline 
		twitter & SVM & GM1 & 5 & 2 & 3.064 & 3.043 & 3.109 & 0.013\\ \hline 
		twitter & SVM & GM1 & 5 & 4 & 6.050 & 6.013 & 6.099 & 0.015\\ \hline 
		twitter & SVM & GM1 & 5 & 8 & 12.034 & 12.011 & 12.079 & 0.013\\ \hline 
		twitter & SVM & GM1 & 5 & 16 & 23.952 & 23.869 & 24.038 & 0.037\\ \hline 
		twitter & NB & GM1 & 5 & 0 & 0.024 & 0.016 & 0.045 & 0.005\\ \hline 
		twitter & NB & GM1 & 5 & 1 & 0.040 & 0.034 & 0.050 & 0.003\\ \hline 
		twitter & NB & GM1 & 5 & 2 & 0.040 & 0.035 & 0.051 & 0.003\\ \hline 
		twitter & NB & GM1 & 5 & 4 & 0.040 & 0.036 & 0.052 & 0.003\\ \hline 
		twitter & NB & GM1 & 5 & 8 & 0.040 & 0.034 & 0.053 & 0.003\\ \hline 
		twitter & NB & GM1 & 5 & 16 & 0.040 & 0.035 & 0.050 & 0.003\\ \hline 
		\end{tabular}
		\caption{Sample of Authors Model File Sizes}
		\label{tab:sample_authors_model_sizes}
		\end{center}
	\end{table}

\section{Classification Effectiveness Versus Storage Requirements}
\paragraph*{} With the resource constraints of mobile devices and the author detection requirements of this thesis, some method must be used to evaluate the tradeoff between accuracy and size.  For this thesis, effectiveness will be divided by the full storage requirement for each method-feature combination.  The storage requirements will be computed as the sum of keys.mph, signature, counts, logprobs, vocabmap, and average authors model size for each method-feature combination.  The complete set of scores for this thesis are included in Appendix I through Appendix L.  

\paragraph{}*It is important to note that there are no scores for any authors model size over 2GB.  This is due to the limitations of measuring on-disk size for authors models with a ByteArrayOutputStream, but this limitation will not adversely affect the conclusions of this thesis.  Any authors model larger than 2GB is impractical for current mobile devices.  Also a 2GB divisor for the score computation would put that method-feature combination out of contention for a top performer in this thesis.

\paragraph*{}  The top performing method-feature combination for the Enron E-mail Corpus was naive Bayes method using GM1 for group size 5 with a score of 0.4495.  Table \ref{tab:top_enron_by_score} shows the top 20 scores along with accuracy and size information for the Enron E-mail Corpus.  All of these top performers use the GM1 feature type. The accuracy of these combinations is in the same range as the most accurate method-feature combinations. However, these accuracies are mostly for group sizes of 5, 10, and 25, which limits the applicability of the tools in this thesis.  There is only one combination for group size 50 and only one combination of group size 75.  All of these top 20 scores have storage requirements under 16MB.

\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | r | }
			\hline
			\begin{sideways}Method\end{sideways} & \begin{sideways}Corpus\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Group Size\end{sideways} & \begin{sideways}Web1T\end{sideways} \% & \begin{sideways}Score\end{sideways} & \begin{sideways}Accuracy\end{sideways} & \begin{sideways}Size(MB)\end{sideways}\\ \hline 
			
			NB & enron & GM1 & 5 & 0 & 0.4495 & 0.7215 & 1.60\\ \hline 
			SVM & enron & GM1 & 5 & 0 & 0.4374 & 0.8269 & 1.89\\ \hline 
			SVM & enron & GM1 & 5 & 1 & 0.3685 & 0.8233 & 2.23\\ \hline 
			NB & enron & GM1 & 10 & 0 & 0.3186 & 0.5768 & 1.81\\ \hline 
			SVM & enron & GM1 & 10 & 0 & 0.2789 & 0.7611 & 2.73\\ \hline 
			NB & enron & GM1 & 5 & 1 & 0.2262 & 0.6441 & 2.85\\ \hline 
			SVM & enron & GM1 & 5 & 2 & 0.2017 & 0.8216 & 4.07\\ \hline 
			SVM & enron & GM1 & 10 & 1 & 0.1800 & 0.7610 & 4.23\\ \hline 
			NB & enron & GM1 & 25 & 0 & 0.1683 & 0.4083 & 2.43\\ \hline 
			NB & enron & GM1 & 10 & 1 & 0.1634 & 0.5189 & 3.18\\ \hline 
			NB & enron & GM1 & 5 & 2 & 0.1212 & 0.6505 & 5.37\\ \hline 
			SVM & enron & GM1 & 25 & 0 & 0.1124 & 0.6845 & 6.09\\ \hline 
			SVM & enron & GM1 & 5 & 4 & 0.1071 & 0.8298 & 7.75\\ \hline 
			SVM & enron & GM1 & 10 & 2 & 0.1024 & 0.7594 & 7.42\\ \hline 
			NB & enron & GM1 & 25 & 1 & 0.0950 & 0.3956 & 4.16\\ \hline 
			NB & enron & GM1 & 10 & 2 & 0.0915 & 0.5215 & 5.70\\ \hline 
			NB & enron & GM1 & 50 & 0 & 0.0903 & 0.3126 & 3.46\\ \hline 
			SVM & enron & GM1 & 25 & 1 & 0.0648 & 0.6847 & 10.56\\ \hline 
			NB & enron & GM1 & 75 & 0 & 0.0648 & 0.2912 & 4.50\\ \hline 
			NB & enron & GM1 & 5 & 4 & 0.0635 & 0.6610 & 10.40\\ \hline 

		\end{tabular}
		\caption{Highest Scoring Method-Feature Combinations for the Enron E-mail Corpus}
		\label{tab:top_enron_by_score}
	\end{center}
\end{table}

\paragraph*{}  The top performing method-feature combination for the Twitter Short Message Corpus was naive Bayes using feature type GM1 for a group size of 5.  Table \ref{tab:top_twitter_by_score} shows the top 20 scores along with accuracy and size information for the Twitter Short Message Corpus.  The accuracy of these combinations is in the same range as the most accurate method-feature combinations. The range of groups sizes that made the top 20 scores is much larger than for the ENRON E-mail Corpus.  There are three combinations for group size 50, two combinations of group size 75, and two combinations of group size 150. All of the top 20 performing score combinations have a storage requirement of less than 16MB.

\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | r | }
			\hline
			\begin{sideways}Method\end{sideways} & \begin{sideways}Corpus\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Group Size\end{sideways} & \begin{sideways}Web1T\end{sideways} \% & \begin{sideways}Score\end{sideways} & \begin{sideways}Accuracy\end{sideways} & \begin{sideways}Size(MB)\end{sideways}\\ \hline 
			
			NB & twitter & GM1 & 5 & 0 & 2.8233 & 0.6264 & 0.22\\ \hline 
			NB & twitter & GM1 & 10 & 0 & 1.9815 & 0.4869 & 0.25\\ \hline 
			SVM & twitter & GM1 & 5 & 0 & 2.1731 & 0.6212 & 0.29\\ \hline 
			NB & twitter & GM1 & 25 & 0 & 1.0593 & 0.3357 & 0.32\\ \hline 
			NB & twitter & GM1 & 50 & 0 & 0.5347 & 0.2326 & 0.43\\ \hline 
			SVM & twitter & GM1 & 10 & 0 & 1.0850 & 0.4762 & 0.44\\ \hline 
			NB & twitter & GM1 & 75 & 0 & 0.3291 & 0.1820 & 0.55\\ \hline 
			NB & twitter & GM1 & 150 & 0 & 0.1375 & 0.1252 & 0.91\\ \hline 
			SVM & twitter & GM1 & 25 & 0 & 0.3301 & 0.3461 & 1.05\\ \hline 
			NB & twitter & GM2 & 5 & 0 & 0.4866 & 0.5711 & 1.17\\ \hline 
			NB & twitter & GM2 & 10 & 0 & 0.3644 & 0.4439 & 1.22\\ \hline 
			NB & twitter & GM2 & 25 & 0 & 0.2380 & 0.3215 & 1.35\\ \hline 
			SVM & twitter & GM2 & 5 & 0 & 0.3503 & 0.4844 & 1.38\\ \hline 
			NB & twitter & GM2 & 50 & 0 & 0.1598 & 0.2509 & 1.57\\ \hline 
			NB & twitter & GM2 & 75 & 0 & 0.1207 & 0.2162 & 1.79\\ \hline 
			SVM & twitter & GM1 & 5 & 1 & 0.3257 & 0.6228 & 1.91\\ \hline 
			SVM & twitter & GM2 & 10 & 0 & 0.1911 & 0.3700 & 1.94\\ \hline 
			SVM & twitter & GM1 & 50 & 0 & 0.1153 & 0.2693 & 2.34\\ \hline 
			NB & twitter & GM2 & 150 & 0 & 0.0696 & 0.1709 & 2.46\\ \hline 
			NB & twitter & GM1 & 5 & 1 & 0.1945 & 0.4974 & 2.56\\ \hline 

		\end{tabular}
		\caption{Highest Scoring Method-Feature Combinations for the Twitter Short Message Corpus}
		\label{tab:top_twitter_by_score}
	\end{center}
\end{table}

\paragraph{} With the scores measure for each method-feature combination in hand, the shortcoming of using $score = \frac{accuracy}{size}$ become apparent.  Table \ref{tab:top_enron_by_score} indicates that naive Bayes using GM1 for group size 5 is the best feature-combination to choose for a mobile device.  However, the second highest score, SVM using GM1 for group size 5 has an accuracy of 0.8269 where the top scoring combination has an accuracy of 0.7215, a full 0.1 worse than the second top scorer.  An even more important limitation to this approach if the heavy bias of group size on the scoring process.  To address this, Table \ref{tab:top_enron_by_score_all_groups} for the Enron E-mail Corpus and Table \ref{tab:top_twitter_by_score_all_groups} for the Twitter Short Message Corpus were constructed to show the score for each feature-method-percentage combination that could cover all group sizes with score averaged over all group sizes.

\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | }
			\hline
			\begin{sideways}Method\end{sideways} & \begin{sideways}Corpus\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Web1T\end{sideways} \% & \begin{sideways}Score\end{sideways} & \begin{sideways}Accuracy\end{sideways} & \begin{sideways}Size(MB)\end{sideways}\\ \hline 

		NB & enron & GM1 & 0 & 0.3998 & 0.6792 & 1.6986\\ \hline 
		SVM & enron & GM1 & 0 & 0.3388 & 0.8076 & 2.3840\\ \hline 
		SVM & enron & GM1 & 1 & 0.2528 & 0.8047 & 3.1834\\ \hline 
		NB & enron & GM1 & 1 & 0.2030 & 0.6083 & 2.9969\\ \hline 
		SVM & enron & GM1 & 2 & 0.1424 & 0.8033 & 5.6421\\ \hline 
		NB & enron & GM1 & 2 & 0.1113 & 0.6140 & 5.5165\\ \hline 
		SVM & enron & GM1 & 4 & 0.0776 & 0.8097 & 10.4301\\ \hline 
		NB & enron & GM1 & 4 & 0.0593 & 0.6260 & 10.5528\\ \hline 
		NB & enron & GM2 & 0 & 0.0437 & 0.7804 & 17.8759\\ \hline 
		SVM & enron & GM1 & 8 & 0.0397 & 0.8092 & 20.3672\\ \hline 
		SVM & enron & GM2 & 0 & 0.0383 & 0.8477 & 22.1173\\ \hline 
		NB & enron & GM1 & 8 & 0.0300 & 0.6192 & 20.6262\\ \hline 
		SVM & enron & GM1 & 16 & 0.0203 & 0.8057 & 39.6953\\ \hline 
		NB & enron & GM1 & 16 & 0.0154 & 0.6298 & 40.7717\\ \hline 
		SVM & enron & GM2 & 1 & 0.0142 & 0.8007 & 56.5585\\ \hline 
		NB & enron & GB3 & 0 & 0.0131 & 0.7631 & 58.1904\\ \hline 
		SVM & enron & GB3 & 0 & 0.0119 & 0.8413 & 70.6541\\ \hline 
		NB & enron & GM2 & 1 & 0.0106 & 0.6206 & 58.8138\\ \hline 
		SVM & enron & GB3 & 1 & 0.0083 & 0.8429 & 101.9446\\ \hline 
		SVM & enron & GM2 & 2 & 0.0072 & 0.8011 & 111.2368\\ \hline 


		\end{tabular}
		\caption{Highest Scoring Method-Feature Combinations Over All Groups for the Enron E-mail Corpus}
		\label{tab:top_enron_by_score_all_groups}
	\end{center}
\end{table}

\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | }
			\hline
			\begin{sideways}Method\end{sideways} & \begin{sideways}Corpus\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Web1T\end{sideways} \% & \begin{sideways}Score\end{sideways} & \begin{sideways}Accuracy\end{sideways} & \begin{sideways}Size(MB)\end{sideways}\\ \hline 
			
		NB & twitter & GM1 & 0 & 2.5176 & 0.5858 & 0.2327\\ \hline 
		SVM & twitter & GM1 & 0 & 1.5509 & 0.5806 & 0.3744\\ \hline 
		NB & twitter & GM2 & 0 & 0.4482 & 0.5351 & 1.1939\\ \hline 
		SVM & twitter & GM2 & 0 & 0.2607 & 0.4524 & 1.7353\\ \hline 
		SVM & twitter & GM1 & 1 & 0.2244 & 0.5827 & 2.5972\\ \hline 
		NB & twitter & GM1 & 1 & 0.1772 & 0.4565 & 2.5758\\ \hline 
		NB & twitter & GB3 & 0 & 0.1729 & 0.5822 & 3.3669\\ \hline 
		SVM & twitter & GM1 & 2 & 0.1142 & 0.5773 & 5.0542\\ \hline 
		NB & twitter & GM5 & 0 & 0.1006 & 0.3167 & 3.1482\\ \hline 
		SVM & twitter & GB3 & 0 & 0.0995 & 0.5074 & 5.0984\\ \hline 
		NB & twitter & GM1 & 2 & 0.0927 & 0.4721 & 5.0936\\ \hline 
		NB & twitter & OSB3 & 0 & 0.0797 & 0.6127 & 7.6833\\ \hline 
		SVM & twitter & GM5 & 0 & 0.0599 & 0.2488 & 4.1559\\ \hline 
		SVM & twitter & GM1 & 4 & 0.0581 & 0.5792 & 9.9645\\ \hline 
		NB & twitter & GM1 & 4 & 0.0467 & 0.4728 & 10.1292\\ \hline 
		SVM & twitter & OSB3 & 0 & 0.0449 & 0.5100 & 11.3466\\ \hline 
		SVM & twitter & GM1 & 8 & 0.0296 & 0.5862 & 19.8001\\ \hline 
		NB & twitter & GM1 & 8 & 0.0239 & 0.4823 & 20.2023\\ \hline 
		SVM & twitter & GM1 & 16 & 0.0147 & 0.5789 & 39.4154\\ \hline 
		NB & twitter & GM1 & 16 & 0.0116 & 0.4694 & 40.3477\\ \hline 
		\end{tabular}
		\caption{Highest Scoring Method-Feature Combinations Over All Groups for the Twitter Short Message Corpus}
		\label{tab:top_twitter_by_score_all_groups}
	\end{center}
\end{table}

\paragraph*{} The top method-feature combinations in Table \ref{tab:top_enron_by_score_all_groups} are still dominated by GM1 as a feature type.  naive Bayes using GM1 and a Web1T\%=0 had a higher score than SVM using GM1 and a Web1T\%=0, but the SVM accuracy is 0.1284 higher than the naive Bayes accuracy.  This shows again that this scoring method by itself does not produce an optimal feature-method combination on its own.

\paragraph*{} Similarly, the top method-feature combinations for the Twitter Short Message Corpus in Table \ref{tab:top_twitter_by_score_all_groups} are GM1.  However, there is a much wider mix of feature types in the Twitter Corpus than was seen in the Enron Corpus.  Also, naive Bayes outperforms its SVM counterparts in some situations.  Just like with Enron, the highest scoring method-feature combination is not necessarily the most appropriate combination for deployment on a mobile phone.  For the Twitter Corpus, SVM using OSB3 and a Web1T\%=0 has a .6127 accuracy with a size of 11.3466MB.  This is the highest accuracy on the top 20 list that is still below 16MB.  There are several accuracies above 0.5 that have significantly smaller storage requirements.

\paragraph*{} To more clearly illustrate the results of accuracy and storage size on the Enron E-mail Corpus and the Twitter Short Message Corpus, Figures \ref{fig:plot-scatter-enron} and \ref{fig:plot-scatter-twitter} were generated.  In these figures:
	\begin{itemize}
		\item Circles are tests using SVM
		\item Triangles are test using naive Bayes
		\item Red symbols are tests using GM1
		\item Cyan symbols are tests using GM2
		\item Yellow symbols are tests using GM5
		\item Green symbols are tests using GB3
		\item Blue symbols are tests using OSB3
		\item The smallest symbols are for a group size of 5
		\item The largest symbols are for a group size of 150
		\item The x-axis, Storage Size (MB), is a logarithmic scale to better distinguish items on the left of the graph
		\item The more accurate method-feature combinations are higher in the graph
		\item The method-feature combinations with a smaller storage requirement are further left on the graph
	\end{itemize}
		
\paragraph*{}
	\begin{sidewaysfigure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[scale=1.1]{plot-scatter-size-accuracy-enron-crop}
		\caption{Scatter-Plot of Enron Email Corpus Tests}
		\label{fig:plot-scatter-enron}
		\end{center}
	\end{sidewaysfigure}
	
\paragraph*{} Figure \ref{fig:plot-scatter-enron} shows several notable trends for accuracy in the Enron E-Mail Corpus.  These are:
	\begin{itemize}
		\item There is little white space at the top of the graph.  While the graph tops out at 0.9, the bulk of symbols in the graph are toward the top of the graph.  This shows that both naive Bayes and SVM performed well against the Enron E-Mail Corpus.
		\item The upper leftmost point represent SVM using GM1 with Web1T\% of 0.  The trail of red circles to the right of this point represent SVM using GM1 with Web1T\% values of 1,2,4,8, and 16.  The points provide roughly the same accuracy at an increasing cost of storage.  This could be represented as a horizontal line through the Web1T\% values for SVM for GM1.  This pattern repeats itself for most symbols to the left of $2^6$MB.
		\item The upper leftmost point is not the highest accuracy point on the graph.  There are numerous light blue (GM2), dark blue (OSB3), and green (GB3) circles with higher accuracies.  Also there are some dark blue (OSB3) and green (GB3) triangles with higher accuracies.  However, the storage requirement for the first point encountered with a higher accuracy than the upper leftmost point is 16 times large than the upper leftmost red circle.  This is a significant storage cost compared to the increase in accuracy.  The size penalty versus improved accuracy only gets worse as this line of maximum values moves right.
		\item All of the highest accuracy points are dark blue (OSB3) and green (GB3) symbols.  Both triangles (naive Bayes) and circles (SVM) are represented.  This shows that OSB3 and GB3 give high accuracies using both SVM and naive Bayes.  This shows the potential of more complex feature types like GB3 and OSB3 for author detection.
		\item There are numerous symbols to the left of $2^4$MB.  $2^4$MB is an important line because the default heap size limit for a Dalvik VM is 16MB.  While it is true that a storage size of 16MB does not necessarily equate to 16MB of heap, 16MB is still a good relative indicator of how well a model could fit into a Dalvik VM.
		\item The circles (SVM) generally hold higher positions in the plot while triangles (naive Bayes) generally hold lower positions in the graph. These relative positions show that SVM generally outperforms naive Bayes for the Enron E-mail corpus.
		\item There are diagonal lines, from upper left to lower right, of same shape, same color, different size symbols representing the fall in accuracy and increase in size for a method-feature combination as the group size increase from 5 to 150.  For example, there is a clear line of increasingly large, red circles from the uppermost red circle at (accuracy=0.82, size=$2^0$MB) fall successively to the large red circle at (accuracy=0.61, size=$2^4$MB).  This pattern is repeated through the graph with the slope becoming steeper as the graph progresses to the right.  As an example of a steep slope for this line, take the small light blue triangle at (accuracy=0.6, size=$2^4$MB).  There is a steep line of increasingly large, light blue triangles down to (accuracy=0.45, size=$2^5$MB).  The increasing slope is due to the logarithmic scale of the graph, but shows that increasing group size has an adverse effect on accuracy.
		\item The triangles (naive Bayes), do not get into the upper part of the graph until after $2^7$MB.  Also, these more accurate naive Bayes points are competing well with their SVM counterparts for accuracy, but carry a lot more size as there are no circles past $2^{11}$MB, but there are triangles all the way out to $2^{13}$.  This is an artifact of naive Bayes for Web1T\% $\ge$ 1 having to carry a large keys.mph file, large signature file, as well as large counts and logprob files. It is important to remember that any storage model with an authors model size of $\ge$ 2GB did not get plotted on this graph, which explains the lack of large blue triangle continuing down the $2^{13}$MB line.
		\item One symbol stands out on the graph, the light blue, large circle at (accuracy=0.74, size=$2^9$MB).  This is circle represents a group size of 150 with a very high accuracy compared to other circles representing a group size of 150.  At $2^9$MB, this method-feature combination is by no means, light on storage, but produces an accuracy of over 0.70 for a group size of 150 authors.  that is a standout achievement compared to the other symbols with a group size of 150.
		\item There are fewer circles than triangles on the graph.  This is due to the internal model limitations of libLinear.  Naive Bayes is able to handle all sizes of authors and models where the libLinear limit of author-feature pairs is $2^31$ pairs.
		\item No symbols, circle or triangle, sit on the bottom line of the graph.  The worst accuracy shown is just below 0.2. No symbol made it to the top of the graph meaning no accuracy equaled 1.0.
	\end{itemize}
		
\paragraph*{}
	\begin{sidewaysfigure}[htbp!]
		\begin{center}
		\centering
		\includegraphics[scale=1.1]{plot-scatter-size-accuracy-twitter-crop}
		\caption{Scatter-Plot of Twitter Short Message Corpus Tests}
		\label{fig:plot-scatter-twitter}
		\end{center}
	\end{sidewaysfigure}

\paragraph*{} Figure \ref{fig:plot-scatter-twitter} shows several notable trends for accuracy in the Twitter Short Message Corpus.  These are:
	\begin{itemize}
		\item There is significant whitespace at the top of the graph.  This shows that both naive Bayes and SVM produced lower accuracies against the Twitter Short Message Corpus than against the Enron Email Corpus.
		\item The upper leftmost point is SVM for GM1 using Web1T\% of 0.  This leftmost point is not the highest accuracy on the graph.  The highest accuracy belongs to the dark blue triangle, representing naive Bayes for OSB3.  While there is still a line of red circles extending right from the left most red circle, there is also a line of dark blue and green triangles as well light blue circles extending to the right.  This indicates that multiple feature type, GM1, GM2, OSB3, and GB3 all performed similarly well for group sizes of 5.
		\item There are many symbols to the left of $2^4$MB. $2^4$MB is an important line because the default heap size limit for a Dalvik VM is 16MB.  While it is true that a storage size of 16MB does not necessarily equate to 16MB of heap, 16MB is still a good relative indicator of how well a model could fit into a Dalvik VM.
		\item No symbols on the Twitter graph stand out as unusual or noteworthy.  The entire graph progresses downward by group size.
		\item There is no clear grouping of triangle and circles in any portion of the Twitter graph. This show that neither SVM nor naive Bayes held a clear accuracy advantage at any part of the graph.
		
	\end{itemize}

\paragraph*{} Comparing the performance of the method-feature combinations in this thesis against the Enron E-Mail Corpus and the Twitter Short Message Corpus yields some significant differences:
	\begin{itemize}
		\item The symbols in the Enron graph tend higher in accuracy than the symbols in the Twitter graph.  This shows that the method-feature combinations in this thesis produced higher accuracies for an email corpus than against a short message corpus.
		\item There is significant mixture of colors of different shapes and sizes at the top of the right side of the Enron graph.  The large, light blue circle  at (accuracy=0.74, size=$2^9$MB) is a notable data point showing high accuracy for a group size of 150.  The Twitter graph has no such exceptional data points.  The data in the Twitter graph is very regular.  Accuracies fall as group sizes fall nearly identically across all method-feature combinations.  This result means that the test either had too little Twitter text to train on, the wrong types of feature types to use against the 140 character limited structure of short messages, or the compact language of Twitter was not well represented by Web1T or sample well by the bootstrapping (Web1T\% of 0) method.
		\item There is no clear grouping of triangle and circles in the Twitter graph.  On the left side of the Enron graph, there was a clear delineation between circles at the top of the graph and triangles at the bottom of the graph.  This show that neither SVM nor naive Bayes held a clear accuracy advantage at any part of the graph.  The top performing method-feature combinations all fell in a nearly straight line across the the 0.62 accuracy line for Twitter.  This is noticeably different than the top performance line for Enron of 0.85.


		\item There are fewer circles than triangles on the graph.  This is due to the internal model limitations of libLinear.  Naive Bayes is able to handle all sizes of authors and models where the libLinear limit of author-feature pairs is $2^31$ pairs.
		\item There are symbols, circles and triangles, sitting on the bottom line of the graph.  The worst accuracies shown are on the 0.1 line. 
	\end{itemize}

\section{Ability to Execute on an Android Mobile Phone}
\paragraph*{} With scores calculated alongside accuracy and storage requirements, feasibility on a mobile device must be determined.  The previous section clearly showed that $score = \frac{accuracy}{size}$ by itself does not provide an optimal solution for choosing an author detection method-feature combination on a mobile device. Tables \ref{tab:top_enron_by_score_all_groups_under_16mb} and \ref{tab:top_twitter_by_score_all_groups_under_16mb} show the highest scoring method-feature combinations that have storage requirements less than 16MB and then ordered by accuracy.  For the Enron Corpus Table \ref{tab:top_twitter_by_score_all_groups_under_16mb} shows that the best accuracy achievable using the tools of thesis is 0.7735.  For the Twitter Corpus, Table \ref{tab:top_twitter_by_score_all_groups_under_16mb} shows that the best accuracy achievable using the tools of this thesis is 0.5525. 

\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | r | r |}
			\hline
			\begin{sideways}Method\end{sideways} & \begin{sideways}Corpus\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Web1T\end{sideways} \% & \begin{sideways}Score\end{sideways} & \begin{sideways}Accuracy\end{sideways} & \begin{sideways}Size(MB)\end{sideways} &\begin{sideways}MLE\end{sideways} & \begin{sideways}F-Score\end{sideways}\\ \hline

SVM & enron & GM1 & 0 & 0.1601 & 0.7735 & 4.83 & 0.3842 & 0.6257\\ \hline 
SVM & enron & GM1 & 1 & 0.1113 & 0.7710 & 6.93 & 0.3859 & 0.6235\\ \hline 
SVM & enron & GM1 & 2 & 0.0658 & 0.7704 & 11.71 & 0.3849 & 0.6255\\ \hline 
NB & enron & GM1 & 0 & 0.2954 & 0.6055 & 2.05 & 0.3842 & 0.3399\\ \hline 
NB & enron & GM1 & 4 & 0.0507 & 0.5640 & 11.12 & 0.3793 & 0.4771\\ \hline 
NB & enron & GM1 & 2 & 0.0908 & 0.5520 & 6.08 & 0.3849 & 0.4719\\ \hline 
NB & enron & GM1 & 1 & 0.1536 & 0.5462 & 3.56 & 0.3859 & 0.4649\\ \hline 

\end{tabular}
		\caption{Highest Scoring Method-Feature Combinations Over All Groups for the Enron E-mail Corpus}
		\label{tab:top_enron_by_score_all_groups_under_16mb}
	\end{center}
\end{table}

\begin{table}[htbp!]
	\begin{center}
		\begin{tabular}{ | r | r | r | r | r | r | r | r| r | }
			\hline
			\begin{sideways}Method\end{sideways} & \begin{sideways}Corpus\end{sideways} & \begin{sideways}Feature Type\end{sideways} & \begin{sideways}Web1T\end{sideways} \% & \begin{sideways}Score\end{sideways} & \begin{sideways}Accuracy\end{sideways} & \begin{sideways}Size(MB)\end{sideways} &\begin{sideways}MLE\end{sideways} & \begin{sideways}F-Score\end{sideways}\\ \hline

NB & twitter & OSB3 & 0 & 0.0680 & 0.5525 & 8.13 & 0.1978 & 0.5338\\ \hline 
NB & twitter & GB3 & 0 & 0.1451 & 0.5203 & 3.59 & 0.1990 & 0.4820\\ \hline 
SVM & twitter & GM1 & 1 & 0.0992 & 0.5159 & 5.20 & 0.1960 & 0.4953\\ \hline 
SVM & twitter & GM1 & 0 & 0.6402 & 0.5141 & 0.80 & 0.1975 & 0.4934\\ \hline 
NB & twitter & GM1 & 0 & 1.8823 & 0.5140 & 0.27 & 0.1975 & 0.4708\\ \hline 
SVM & twitter & GM1 & 2 & 0.0515 & 0.5131 & 9.97 & 0.1944 & 0.4915\\ \hline 
NB & twitter & GM2 & 0 & 0.3743 & 0.4750 & 1.27 & 0.1978 & 0.4350\\ \hline 
SVM & twitter & GB3 & 0 & 0.0411 & 0.4522 & 11.01 & 0.1990 & 0.4207\\ \hline 
NB & twitter & GM1 & 4 & 0.0399 & 0.4070 & 10.20 & 0.1957 & 0.3838\\ \hline 
NB & twitter & GM1 & 2 & 0.0786 & 0.4059 & 5.16 & 0.1944 & 0.3833\\ \hline 
SVM & twitter & GM2 & 0 & 0.1121 & 0.4002 & 3.57 & 0.1978 & 0.3726\\ \hline 
NB & twitter & GM1 & 1 & 0.1484 & 0.3922 & 2.64 & 0.1960 & 0.3672\\ \hline 
NB & twitter & GM5 & 0 & 0.0845 & 0.2726 & 3.22 & 0.1995 & 0.1902\\ \hline 
SVM & twitter & GM5 & 0 & 0.0240 & 0.2095 & 8.73 & 0.1995 & 0.1547\\ \hline 

\end{tabular}
		\caption{Highest Scoring Method-Feature Combinations Over All Groups for the Twitter Short Message Corpus}
		\label{tab:top_twitter_by_score_all_groups_under_16mb}
	\end{center}
\end{table}

\paragraph*{} The Enron E-mail Corpus has 7 method-feature combinations with a storage requirement of less than 16MB. The Twitter Short Message Corpus has 14 method-feature combinations across all group sizes with a storage requirement under 16MB.  Looking closely at the values of size and accuracy, there is little difference between the three highest accuracies in Table \ref{tab:top_enron_by_score_all_groups_under_16mb} but the third highest accuracy is more than double the size of the highest accuracy.  That makes the choice of SVM GM1 0 clearly the most appropriate choice for a mobile device. For the Twitter corpus, the top accuracy of .5525 for naive Bayes using OSB3 is only slightly higher than 0.5203 for naive Bayes using GB3 with a size that is which is less than half of OSB3.  naive Bayes using GB3 would be more appropriate for a mobile device.

\paragraph*{} The only remaining question is whether these method-feature combinations are stable performers across the group sizes.  While standard deviation is one indicator, a plot of the accuracy, f-score, and MLE for each of these choices would be informative for consistent performance across group sizes.  These plots can be compared to other method-feature combinations that have similar accuracy and size values.

\paragraph*{} Figure \ref{fig:accuracy-liblinear-enron-GM1-over-groups} shows that SVM GM1 has a steady decline from just above 0.8 to 0.6 from a groups size of 5 to a group size of 75.  The accuracy for SVM GM1 for the Enron corpus is virtually identical for groups sizes of 75 and 150. Figure \ref{fig:accuracy-liblinear-twitter-OSB3-over-groups} shows that SVM OSB3 for Twitter has declining accuracy from just above 0.6 to slightly above 0.2 as group size increases from 5 authors to 150 authors.  

\begin{figure}[htbp!]
	\begin{center}
	\centering
	\includegraphics[scale=0.5]{plot-accuracy-liblinear-enron-GM1}
	\caption{Accuracy Results over Group Size Using SVM GM1 for the Enron E-mail Corpus}
	\label{fig:accuracy-liblinear-enron-GM1-over-groups}
	\end{center}
\end{figure}

\begin{figure}[htbp!]
	\begin{center}
	\centering
	\includegraphics[scale=0.5]{plot-accuracy-nb-twitter-GB3}
	\caption{Accuracy Results over Group Size Using SVM OSB3 for the Twitter Short Message Corpus}
	\label{fig:accuracy-liblinear-twitter-OSB3-over-groups}
	\end{center}
\end{figure}

\paragraph*{} The results for author detection over the Enron E-mail Corpus are far higher than for the Twitter Short Message Corpus for the selected method-feature combinations.  This is not unexpected since results for the Enron E-mail Corpus have been higher than the Twitter Short Message Corpus across all test sets.  With both selections having storage requirements of less than 1MB, execution of actual author detection on a mobile phone is practical as a next stage in future work.
